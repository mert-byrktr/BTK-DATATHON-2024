{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "359866b6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-15T18:14:33.977790Z",
     "iopub.status.busy": "2024-09-15T18:14:33.977475Z",
     "iopub.status.idle": "2024-09-15T18:15:07.301716Z",
     "shell.execute_reply": "2024-09-15T18:15:07.300723Z"
    },
    "papermill": {
     "duration": 33.337056,
     "end_time": "2024-09-15T18:15:07.303991",
     "exception": false,
     "start_time": "2024-09-15T18:14:33.966935",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "cuml 24.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\r\n",
      "aiobotocore 2.13.2 requires botocore<1.34.132,>=1.34.70, but you have botocore 1.29.165 which is incompatible.\r\n",
      "bigframes 0.22.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.10.0, but you have google-cloud-bigquery 2.34.4 which is incompatible.\r\n",
      "bigframes 0.22.0 requires google-cloud-storage>=2.0.0, but you have google-cloud-storage 1.44.0 which is incompatible.\r\n",
      "bigframes 0.22.0 requires pandas<2.1.4,>=1.5.0, but you have pandas 2.2.2 which is incompatible.\r\n",
      "dataproc-jupyter-plugin 0.1.79 requires pydantic~=1.10.0, but you have pydantic 2.8.2 which is incompatible.\r\n",
      "libpysal 4.9.2 requires packaging>=22, but you have packaging 21.3 which is incompatible.\r\n",
      "libpysal 4.9.2 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\r\n",
      "momepy 0.7.2 requires shapely>=2, but you have shapely 1.8.5.post1 which is incompatible.\r\n",
      "pointpats 2.5.0 requires shapely>=2, but you have shapely 1.8.5.post1 which is incompatible.\r\n",
      "spaghetti 1.7.6 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\r\n",
      "spopt 0.6.1 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\r\n",
      "tsfresh 0.20.3 requires scipy>=1.14.0; python_version >= \"3.10\", but you have scipy 1.12.0 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install autogluon.tabular==1.1.1 -q  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ef42a0b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-15T18:15:07.323674Z",
     "iopub.status.busy": "2024-09-15T18:15:07.323369Z",
     "iopub.status.idle": "2024-09-15T18:15:07.327423Z",
     "shell.execute_reply": "2024-09-15T18:15:07.326593Z"
    },
    "papermill": {
     "duration": 0.016296,
     "end_time": "2024-09-15T18:15:07.329479",
     "exception": false,
     "start_time": "2024-09-15T18:15:07.313183",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip uninstall lightgbm -y -q\n",
    "# !pip install lightgbm --install -option=--gpu -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5521c66",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-15T18:15:07.347689Z",
     "iopub.status.busy": "2024-09-15T18:15:07.347402Z",
     "iopub.status.idle": "2024-09-15T18:15:21.929264Z",
     "shell.execute_reply": "2024-09-15T18:15:21.928055Z"
    },
    "papermill": {
     "duration": 14.593672,
     "end_time": "2024-09-15T18:15:21.931712",
     "exception": false,
     "start_time": "2024-09-15T18:15:07.338040",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install rapidfuzz -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "016abe16",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-09-15T18:15:21.950875Z",
     "iopub.status.busy": "2024-09-15T18:15:21.950541Z",
     "iopub.status.idle": "2024-09-15T18:15:32.946108Z",
     "shell.execute_reply": "2024-09-15T18:15:32.945098Z"
    },
    "papermill": {
     "duration": 11.007739,
     "end_time": "2024-09-15T18:15:32.948512",
     "exception": false,
     "start_time": "2024-09-15T18:15:21.940773",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from autogluon.tabular import TabularPredictor\n",
    "# from autogluon.features.generators import AutoMLPipelineFeatureGenerator\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "from rapidfuzz import process, fuzz\n",
    "\n",
    "from textblob import TextBlob\n",
    "\n",
    "import re\n",
    "\n",
    "import spacy\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "\n",
    "import lightgbm as lgb\n",
    "import catboost as cb\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "import json\n",
    "\n",
    "\n",
    "from math import sqrt\n",
    "\n",
    "from lightgbm import early_stopping, log_evaluation\n",
    "\n",
    "\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option(\"display.max_rows\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "57e359d5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-15T18:15:32.968035Z",
     "iopub.status.busy": "2024-09-15T18:15:32.967435Z",
     "iopub.status.idle": "2024-09-15T18:15:34.215809Z",
     "shell.execute_reply": "2024-09-15T18:15:34.214845Z"
    },
    "papermill": {
     "duration": 1.26038,
     "end_time": "2024-09-15T18:15:34.217932",
     "exception": false,
     "start_time": "2024-09-15T18:15:32.957552",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Basvuru Yili</th>\n",
       "      <th>Degerlendirme Puani</th>\n",
       "      <th>Cinsiyet</th>\n",
       "      <th>Dogum Tarihi</th>\n",
       "      <th>Dogum Yeri</th>\n",
       "      <th>Ikametgah Sehri</th>\n",
       "      <th>Universite Adi</th>\n",
       "      <th>Universite Turu</th>\n",
       "      <th>Burslu ise Burs Yuzdesi</th>\n",
       "      <th>Burs Aliyor mu?</th>\n",
       "      <th>Bölüm</th>\n",
       "      <th>Universite Kacinci Sinif</th>\n",
       "      <th>Universite Not Ortalamasi</th>\n",
       "      <th>Daha Once Baska Bir Universiteden Mezun Olmus</th>\n",
       "      <th>Lise Adi</th>\n",
       "      <th>Lise Adi Diger</th>\n",
       "      <th>Lise Sehir</th>\n",
       "      <th>Lise Turu</th>\n",
       "      <th>Lise Bolumu</th>\n",
       "      <th>Lise Bolum Diger</th>\n",
       "      <th>Lise Mezuniyet Notu</th>\n",
       "      <th>Baska Bir Kurumdan Burs Aliyor mu?</th>\n",
       "      <th>Burs Aldigi Baska Kurum</th>\n",
       "      <th>Baska Kurumdan Aldigi Burs Miktari</th>\n",
       "      <th>Anne Egitim Durumu</th>\n",
       "      <th>Anne Calisma Durumu</th>\n",
       "      <th>Anne Sektor</th>\n",
       "      <th>Baba Egitim Durumu</th>\n",
       "      <th>Baba Calisma Durumu</th>\n",
       "      <th>Baba Sektor</th>\n",
       "      <th>Kardes Sayisi</th>\n",
       "      <th>Girisimcilik Kulupleri Tarzi Bir Kulube Uye misiniz?</th>\n",
       "      <th>Uye Oldugunuz Kulubun Ismi</th>\n",
       "      <th>Profesyonel Bir Spor Daliyla Mesgul musunuz?</th>\n",
       "      <th>Spor Dalindaki Rolunuz Nedir?</th>\n",
       "      <th>Aktif olarak bir STK üyesi misiniz?</th>\n",
       "      <th>Hangi STK'nin Uyesisiniz?</th>\n",
       "      <th>Stk Projesine Katildiniz Mi?</th>\n",
       "      <th>Girisimcilikle Ilgili Deneyiminiz Var Mi?</th>\n",
       "      <th>Girisimcilikle Ilgili Deneyiminizi Aciklayabilir misiniz?</th>\n",
       "      <th>Ingilizce Biliyor musunuz?</th>\n",
       "      <th>Ingilizce Seviyeniz?</th>\n",
       "      <th>Daha Önceden Mezun Olunduysa, Mezun Olunan Üniversite</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014</td>\n",
       "      <td>52.0</td>\n",
       "      <td>Erkek</td>\n",
       "      <td>4/6/1994</td>\n",
       "      <td>Altindag, Ankara</td>\n",
       "      <td>Ankara</td>\n",
       "      <td>İHSAN DOĞRAMACI BİLKENT</td>\n",
       "      <td>Özel</td>\n",
       "      <td>100.0</td>\n",
       "      <td>Evet</td>\n",
       "      <td>Bilgisayar Muhendisligi</td>\n",
       "      <td>3</td>\n",
       "      <td>3.50-3</td>\n",
       "      <td>Hayır</td>\n",
       "      <td>Ankara Ataturk Anadolu Lisesi</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ankara</td>\n",
       "      <td>Anadolu lisesi</td>\n",
       "      <td>MF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.50-3</td>\n",
       "      <td>Hayır</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Üniversite</td>\n",
       "      <td>Hayır</td>\n",
       "      <td>0</td>\n",
       "      <td>Üniversite</td>\n",
       "      <td>Emekli</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Evet</td>\n",
       "      <td>Bilkent IEEE Bilgisayar Toplulugu 2013-2014 Ba...</td>\n",
       "      <td>Evet</td>\n",
       "      <td>Diğer</td>\n",
       "      <td>Hayır</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Evet</td>\n",
       "      <td>Hayır</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014</td>\n",
       "      <td>30.0</td>\n",
       "      <td>Erkek</td>\n",
       "      <td>6/11/1993</td>\n",
       "      <td>Üsküdar</td>\n",
       "      <td>İstanbul</td>\n",
       "      <td>İHSAN DOĞRAMACI BİLKENT</td>\n",
       "      <td>Özel</td>\n",
       "      <td>100.0</td>\n",
       "      <td>Hayır</td>\n",
       "      <td>Elektrik Elektronik Mühendisliği</td>\n",
       "      <td>3</td>\n",
       "      <td>3.00-2.50</td>\n",
       "      <td>Hayır</td>\n",
       "      <td>Betül Can Anadolu Lisesi</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ankara</td>\n",
       "      <td>Anadolu lisesi</td>\n",
       "      <td>MF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.00 - 4.00</td>\n",
       "      <td>Hayır</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Üniversite</td>\n",
       "      <td>Evet</td>\n",
       "      <td>Kamu</td>\n",
       "      <td>Yüksek Lisans / Doktora</td>\n",
       "      <td>Emekli</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Hayır</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hayır</td>\n",
       "      <td>0</td>\n",
       "      <td>Hayır</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Evet</td>\n",
       "      <td>Evet</td>\n",
       "      <td>Bilkent Cyberparkta bir şirkette Türkiye nin i...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014</td>\n",
       "      <td>18.0</td>\n",
       "      <td>Erkek</td>\n",
       "      <td>1/15/1986</td>\n",
       "      <td>Samsun</td>\n",
       "      <td>İstanbul</td>\n",
       "      <td>ULUSLARARASI KIBRIS ÜNİVERSİTESİ</td>\n",
       "      <td>Özel</td>\n",
       "      <td>100.0</td>\n",
       "      <td>Hayır</td>\n",
       "      <td>Finans Yönetimi ve Pazarlama</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hayır</td>\n",
       "      <td>Batem</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ankara</td>\n",
       "      <td>Meslek lisesi</td>\n",
       "      <td>Elektirk</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.50-3</td>\n",
       "      <td>Hayır</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>İlkokul Mezunu</td>\n",
       "      <td>Hayır</td>\n",
       "      <td>0</td>\n",
       "      <td>İlkokul Mezunu</td>\n",
       "      <td>Evet</td>\n",
       "      <td>Özel Sektör</td>\n",
       "      <td>6</td>\n",
       "      <td>Evet</td>\n",
       "      <td>Tema</td>\n",
       "      <td>Hayır</td>\n",
       "      <td>0</td>\n",
       "      <td>Hayır</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hayır</td>\n",
       "      <td>Hayır</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014</td>\n",
       "      <td>40.0</td>\n",
       "      <td>Erkek</td>\n",
       "      <td>6/4/1991</td>\n",
       "      <td>Diyarbakır</td>\n",
       "      <td>İstanbul</td>\n",
       "      <td>İSTANBUL ŞEHİR ÜNİVERSİTESİ</td>\n",
       "      <td>Özel</td>\n",
       "      <td>100.0</td>\n",
       "      <td>Evet</td>\n",
       "      <td>Bilgisayar Mühendisliği</td>\n",
       "      <td>3</td>\n",
       "      <td>3.00-2.50</td>\n",
       "      <td>Hayır</td>\n",
       "      <td>Cumhuriyet Fen Lisesi</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Diyarbakır</td>\n",
       "      <td>Fen lisesi</td>\n",
       "      <td>Sayısal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.50-3</td>\n",
       "      <td>Hayır</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>İlkokul Mezunu</td>\n",
       "      <td>Hayır</td>\n",
       "      <td>0</td>\n",
       "      <td>Üniversite</td>\n",
       "      <td>Emekli</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>Evet</td>\n",
       "      <td>Güzel Konuşma ve yazma kulübü</td>\n",
       "      <td>Hayır</td>\n",
       "      <td>0</td>\n",
       "      <td>Hayır</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Evet</td>\n",
       "      <td>Hayır</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014</td>\n",
       "      <td>24.0</td>\n",
       "      <td>Erkek</td>\n",
       "      <td>2 Kasim 1992</td>\n",
       "      <td>Ankara/Altındağ</td>\n",
       "      <td>Ankara</td>\n",
       "      <td>TURGUT ÖZAL ÜNİVERSİTESİ</td>\n",
       "      <td>Özel</td>\n",
       "      <td>100.0</td>\n",
       "      <td>Evet</td>\n",
       "      <td>Siyaset Bilimi ve Uluslararası ilişkiler</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.00-2.50</td>\n",
       "      <td>Hayır</td>\n",
       "      <td>Samanyolu Lisesi</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ankara</td>\n",
       "      <td>Özel lisesi</td>\n",
       "      <td>TM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.00 - 4.00</td>\n",
       "      <td>Hayır</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>İlkokul Mezunu</td>\n",
       "      <td>Hayır</td>\n",
       "      <td>0</td>\n",
       "      <td>Üniversite</td>\n",
       "      <td>Emekli</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Hayır</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hayır</td>\n",
       "      <td>0</td>\n",
       "      <td>Hayır</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hayır</td>\n",
       "      <td>Hayır</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Basvuru Yili  Degerlendirme Puani Cinsiyet  Dogum Tarihi        Dogum Yeri Ikametgah Sehri                    Universite Adi Universite Turu  Burslu ise Burs Yuzdesi Burs Aliyor mu?                                     Bölüm Universite Kacinci Sinif Universite Not Ortalamasi Daha Once Baska Bir Universiteden Mezun Olmus                       Lise Adi Lise Adi Diger  Lise Sehir       Lise Turu Lise Bolumu Lise Bolum Diger Lise Mezuniyet Notu Baska Bir Kurumdan Burs Aliyor mu? Burs Aldigi Baska Kurum Baska Kurumdan Aldigi Burs Miktari Anne Egitim Durumu Anne Calisma Durumu Anne Sektor       Baba Egitim Durumu Baba Calisma Durumu  Baba Sektor Kardes Sayisi Girisimcilik Kulupleri Tarzi Bir Kulube Uye misiniz?                         Uye Oldugunuz Kulubun Ismi Profesyonel Bir Spor Daliyla Mesgul musunuz? Spor Dalindaki Rolunuz Nedir? Aktif olarak bir STK üyesi misiniz? Hangi STK'nin Uyesisiniz? Stk Projesine Katildiniz Mi? Girisimcilikle Ilgili Deneyiminiz Var Mi?  \\\n",
       "0          2014                 52.0    Erkek      4/6/1994  Altindag, Ankara          Ankara           İHSAN DOĞRAMACI BİLKENT            Özel                    100.0            Evet                   Bilgisayar Muhendisligi                        3                    3.50-3                                         Hayır  Ankara Ataturk Anadolu Lisesi            NaN      Ankara  Anadolu lisesi          MF              NaN              3.50-3                              Hayır                     NaN                                NaN         Üniversite               Hayır           0               Üniversite              Emekli            0             1                                               Evet    Bilkent IEEE Bilgisayar Toplulugu 2013-2014 Ba...                                         Evet                         Diğer                               Hayır                       NaN                         Evet                                     Hayır   \n",
       "1          2014                 30.0    Erkek     6/11/1993           Üsküdar        İstanbul           İHSAN DOĞRAMACI BİLKENT            Özel                    100.0           Hayır          Elektrik Elektronik Mühendisliği                        3                 3.00-2.50                                         Hayır       Betül Can Anadolu Lisesi            NaN      Ankara  Anadolu lisesi          MF              NaN         3.00 - 4.00                              Hayır                     NaN                                NaN         Üniversite                Evet        Kamu  Yüksek Lisans / Doktora              Emekli            0             1                                              Hayır                                                  NaN                                        Hayır                             0                               Hayır                       NaN                         Evet                                      Evet   \n",
       "2          2014                 18.0    Erkek     1/15/1986            Samsun        İstanbul  ULUSLARARASI KIBRIS ÜNİVERSİTESİ            Özel                    100.0           Hayır              Finans Yönetimi ve Pazarlama                        1                       NaN                                         Hayır                          Batem            NaN      Ankara   Meslek lisesi    Elektirk              NaN              3.50-3                              Hayır                     NaN                                NaN     İlkokul Mezunu               Hayır           0           İlkokul Mezunu                Evet  Özel Sektör             6                                               Evet                                                 Tema                                        Hayır                             0                               Hayır                       NaN                        Hayır                                     Hayır   \n",
       "3          2014                 40.0    Erkek      6/4/1991        Diyarbakır        İstanbul       İSTANBUL ŞEHİR ÜNİVERSİTESİ            Özel                    100.0            Evet                   Bilgisayar Mühendisliği                        3                 3.00-2.50                                         Hayır          Cumhuriyet Fen Lisesi            NaN  Diyarbakır      Fen lisesi     Sayısal              NaN              3.50-3                              Hayır                     NaN                                NaN     İlkokul Mezunu               Hayır           0               Üniversite              Emekli            0            10                                               Evet                        Güzel Konuşma ve yazma kulübü                                        Hayır                             0                               Hayır                       NaN                         Evet                                     Hayır   \n",
       "4          2014                 24.0    Erkek  2 Kasim 1992   Ankara/Altındağ          Ankara          TURGUT ÖZAL ÜNİVERSİTESİ            Özel                    100.0            Evet  Siyaset Bilimi ve Uluslararası ilişkiler                      NaN                 3.00-2.50                                         Hayır               Samanyolu Lisesi            NaN      Ankara     Özel lisesi          TM              NaN         3.00 - 4.00                              Hayır                     NaN                                NaN     İlkokul Mezunu               Hayır           0               Üniversite              Emekli            0             1                                              Hayır                                                  NaN                                        Hayır                             0                               Hayır                       NaN                        Hayır                                     Hayır   \n",
       "\n",
       "  Girisimcilikle Ilgili Deneyiminizi Aciklayabilir misiniz? Ingilizce Biliyor musunuz? Ingilizce Seviyeniz? Daha Önceden Mezun Olunduysa, Mezun Olunan Üniversite  id  \n",
       "0                                                NaN                               NaN                  NaN                                                NaN      0  \n",
       "1  Bilkent Cyberparkta bir şirkette Türkiye nin i...                               NaN                  NaN                                                NaN      1  \n",
       "2                                                NaN                               NaN                  NaN                                                NaN      2  \n",
       "3                                                NaN                               NaN                  NaN                                                NaN      3  \n",
       "4                                                NaN                               NaN                  NaN                                                NaN      4  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv('/kaggle/input/datathon-2024/train.csv')\n",
    "test_df = pd.read_csv('/kaggle/input/datathon-2024/test_x.csv')\n",
    "il_ilce = pd.read_csv('/kaggle/input/trkiye-il-ile-listesi/il_ilce.csv')\n",
    "\n",
    "stopwords = '/kaggle/input/tr-trke-stopwords-turkish/turkce_stopwords.json'\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "639637b0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-15T18:15:34.237965Z",
     "iopub.status.busy": "2024-09-15T18:15:34.237639Z",
     "iopub.status.idle": "2024-09-15T18:15:34.247268Z",
     "shell.execute_reply": "2024-09-15T18:15:34.246241Z"
    },
    "papermill": {
     "duration": 0.02182,
     "end_time": "2024-09-15T18:15:34.249242",
     "exception": false,
     "start_time": "2024-09-15T18:15:34.227422",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'acaba', 'acep', 'adamakıllı', 'adeta', 'ait', 'altmýþ', 'altmış', 'altı', 'ama', 'amma', 'anca', 'ancak', 'arada', 'artýk', 'aslında', 'aynen', 'ayrıca', 'az', 'açıkça', 'açıkçası', 'bana', 'bari', 'bazen', 'bazý', 'bazı', 'başkası', 'baţka', 'belki', 'ben', 'benden', 'beni', 'benim', 'beri', 'beriki', 'beş', 'beş', 'beţ', 'bilcümle', 'bile', 'bin', 'binaen', 'binaenaleyh', 'bir', 'biraz', 'birazdan', 'birbiri', 'birden', 'birdenbire', 'biri', 'birice', 'birileri', 'birisi', 'birkaç', 'birkaçı', 'birkez', 'birlikte', 'birçok', 'birçoğu', 'birþey', 'birþeyi', 'birşey', 'birşeyi', 'birţey', 'bitevi', 'biteviye', 'bittabi', 'biz', 'bizatihi', 'bizce', 'bizcileyin', 'bizden', 'bize', 'bizi', 'bizim', 'bizimki', 'bizzat', 'boşuna', 'bu', 'buna', 'bunda', 'bundan', 'bunlar', 'bunları', 'bunların', 'bunu', 'bunun', 'buracıkta', 'burada', 'buradan', 'burası', 'böyle', 'böylece', 'böylecene', 'böylelikle', 'böylemesine', 'böylesine', 'büsbütün', 'bütün', 'cuk', 'cümlesi', 'da', 'daha', 'dahi', 'dahil', 'dahilen', 'daima', 'dair', 'dayanarak', 'de', 'defa', 'dek', 'demin', 'demincek', 'deminden', 'denli', 'derakap', 'derhal', 'derken', 'deđil', 'değil', 'değin', 'diye', 'diđer', 'diğer', 'diğeri', 'doksan', 'dokuz', 'dolayı', 'dolayısıyla', 'doğru', 'dört', 'edecek', 'eden', 'ederek', 'edilecek', 'ediliyor', 'edilmesi', 'ediyor', 'elbet', 'elbette', 'elli', 'emme', 'en', 'enikonu', 'epey', 'epeyce', 'epeyi', 'esasen', 'esnasında', 'etmesi', 'etraflı', 'etraflıca', 'etti', 'ettiği', 'ettiğini', 'evleviyetle', 'evvel', 'evvela', 'evvelce', 'evvelden', 'evvelemirde', 'evveli', 'eđer', 'eğer', 'fakat', 'filanca', 'gah', 'gayet', 'gayetle', 'gayri', 'gayrı', 'gelgelelim', 'gene', 'gerek', 'gerçi', 'geçende', 'geçenlerde', 'gibi', 'gibilerden', 'gibisinden', 'gine', 'göre', 'gırla', 'hakeza', 'halbuki', 'halen', 'halihazırda', 'haliyle', 'handiyse', 'hangi', 'hangisi', 'hani', 'hariç', 'hasebiyle', 'hasılı', 'hatta', 'hele', 'hem', 'henüz', 'hep', 'hepsi', 'her', 'herhangi', 'herkes', 'herkesin', 'hiç', 'hiçbir', 'hiçbiri', 'hoş', 'hulasaten', 'iken', 'iki', 'ila', 'ile', 'ilen', 'ilgili', 'ilk', 'illa', 'illaki', 'imdi', 'indinde', 'inen', 'insermi', 'ise', 'ister', 'itibaren', 'itibariyle', 'itibarıyla', 'iyi', 'iyice', 'iyicene', 'için', 'iş', 'işte', 'iţte', 'kadar', 'kaffesi', 'kah', 'kala', 'kanýmca', 'karşın', 'katrilyon', 'kaynak', 'kaçı', 'kelli', 'kendi', 'kendilerine', 'kendini', 'kendisi', 'kendisine', 'kendisini', 'kere', 'kez', 'keza', 'kezalik', 'keşke', 'keţke', 'ki', 'kim', 'kimden', 'kime', 'kimi', 'kimisi', 'kimse', 'kimsecik', 'kimsecikler', 'külliyen', 'kýrk', 'kýsaca', 'kırk', 'kısaca', 'lakin', 'leh', 'lütfen', 'maada', 'madem', 'mademki', 'mamafih', 'mebni', 'međer', 'meğer', 'meğerki', 'meğerse', 'milyar', 'milyon', 'mu', 'mü', 'mý', 'mı', 'nasýl', 'nasıl', 'nasılsa', 'nazaran', 'naşi', 'ne', 'neden', 'nedeniyle', 'nedenle', 'nedense', 'nerde', 'nerden', 'nerdeyse', 'nere', 'nerede', 'nereden', 'neredeyse', 'neresi', 'nereye', 'netekim', 'neye', 'neyi', 'neyse', 'nice', 'nihayet', 'nihayetinde', 'nitekim', 'niye', 'niçin', 'o', 'olan', 'olarak', 'oldu', 'olduklarını', 'oldukça', 'olduğu', 'olduğunu', 'olmadı', 'olmadığı', 'olmak', 'olması', 'olmayan', 'olmaz', 'olsa', 'olsun', 'olup', 'olur', 'olursa', 'oluyor', 'on', 'ona', 'onca', 'onculayın', 'onda', 'ondan', 'onlar', 'onlardan', 'onlari', 'onlarýn', 'onları', 'onların', 'onu', 'onun', 'oracık', 'oracıkta', 'orada', 'oradan', 'oranca', 'oranla', 'oraya', 'otuz', 'oysa', 'oysaki', 'pek', 'pekala', 'peki', 'pekçe', 'peyderpey', 'rağmen', 'sadece', 'sahi', 'sahiden', 'sana', 'sanki', 'sekiz', 'seksen', 'sen', 'senden', 'seni', 'senin', 'siz', 'sizden', 'sizi', 'sizin', 'sonra', 'sonradan', 'sonraları', 'sonunda', 'tabii', 'tam', 'tamam', 'tamamen', 'tamamıyla', 'tarafından', 'tek', 'trilyon', 'tüm', 'var', 'vardı', 'vasıtasıyla', 've', 'velev', 'velhasıl', 'velhasılıkelam', 'veya', 'veyahut', 'ya', 'yahut', 'yakinen', 'yakında', 'yakından', 'yakınlarda', 'yalnız', 'yalnızca', 'yani', 'yapacak', 'yapmak', 'yaptı', 'yaptıkları', 'yaptığı', 'yaptığını', 'yapılan', 'yapılması', 'yapıyor', 'yedi', 'yeniden', 'yenilerde', 'yerine', 'yetmiþ', 'yetmiş', 'yetmiţ', 'yine', 'yirmi', 'yok', 'yoksa', 'yoluyla', 'yüz', 'yüzünden', 'zarfında', 'zaten', 'zati', 'zira', 'çabuk', 'çabukça', 'çeşitli', 'çok', 'çokları', 'çoklarınca', 'çokluk', 'çoklukla', 'çokça', 'çoğu', 'çoğun', 'çoğunca', 'çoğunlukla', 'çünkü', 'öbür', 'öbürkü', 'öbürü', 'önce', 'önceden', 'önceleri', 'öncelikle', 'öteki', 'ötekisi', 'öyle', 'öylece', 'öylelikle', 'öylemesine', 'öz', 'üzere', 'üç', 'þey', 'þeyden', 'þeyi', 'þeyler', 'þu', 'þuna', 'þunda', 'þundan', 'þunu', 'şayet', 'şey', 'şeyden', 'şeyi', 'şeyler', 'şu', 'şuna', 'şuncacık', 'şunda', 'şundan', 'şunlar', 'şunları', 'şunu', 'şunun', 'şura', 'şuracık', 'şuracıkta', 'şurası', 'şöyle', 'ţayet', 'ţimdi', 'ţu', 'ţöyle']\n",
      "504\n"
     ]
    }
   ],
   "source": [
    "with open(stopwords, 'r', encoding='utf-8') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "stop_words_list = data.get('stopwords', [])\n",
    "\n",
    "print(stop_words_list)\n",
    "print(len(stop_words_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "341b24c6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-15T18:15:34.269146Z",
     "iopub.status.busy": "2024-09-15T18:15:34.268844Z",
     "iopub.status.idle": "2024-09-15T18:15:34.484678Z",
     "shell.execute_reply": "2024-09-15T18:15:34.483683Z"
    },
    "papermill": {
     "duration": 0.228274,
     "end_time": "2024-09-15T18:15:34.486913",
     "exception": false,
     "start_time": "2024-09-15T18:15:34.258639",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 65125 entries, 0 to 65124\n",
      "Data columns (total 44 columns):\n",
      " #   Column                                                     Non-Null Count  Dtype  \n",
      "---  ------                                                     --------------  -----  \n",
      " 0   Basvuru Yili                                               65125 non-null  int64  \n",
      " 1   Degerlendirme Puani                                        65124 non-null  float64\n",
      " 2   Cinsiyet                                                   64956 non-null  object \n",
      " 3   Dogum Tarihi                                               64948 non-null  object \n",
      " 4   Dogum Yeri                                                 64334 non-null  object \n",
      " 5   Ikametgah Sehri                                            63088 non-null  object \n",
      " 6   Universite Adi                                             64993 non-null  object \n",
      " 7   Universite Turu                                            64870 non-null  object \n",
      " 8   Burslu ise Burs Yuzdesi                                    22440 non-null  float64\n",
      " 9   Burs Aliyor mu?                                            65125 non-null  object \n",
      " 10  Bölüm                                                      64894 non-null  object \n",
      " 11  Universite Kacinci Sinif                                   64751 non-null  object \n",
      " 12  Universite Not Ortalamasi                                  62372 non-null  object \n",
      " 13  Daha Once Baska Bir Universiteden Mezun Olmus              27780 non-null  object \n",
      " 14  Lise Adi                                                   64741 non-null  object \n",
      " 15  Lise Adi Diger                                             4733 non-null   object \n",
      " 16  Lise Sehir                                                 64071 non-null  object \n",
      " 17  Lise Turu                                                  64278 non-null  object \n",
      " 18  Lise Bolumu                                                64116 non-null  object \n",
      " 19  Lise Bolum Diger                                           1526 non-null   object \n",
      " 20  Lise Mezuniyet Notu                                        59208 non-null  object \n",
      " 21  Baska Bir Kurumdan Burs Aliyor mu?                         64894 non-null  object \n",
      " 22  Burs Aldigi Baska Kurum                                    21148 non-null  object \n",
      " 23  Baska Kurumdan Aldigi Burs Miktari                         20963 non-null  object \n",
      " 24  Anne Egitim Durumu                                         64719 non-null  object \n",
      " 25  Anne Calisma Durumu                                        53229 non-null  object \n",
      " 26  Anne Sektor                                                30588 non-null  object \n",
      " 27  Baba Egitim Durumu                                         64118 non-null  object \n",
      " 28  Baba Calisma Durumu                                        52507 non-null  object \n",
      " 29  Baba Sektor                                                44747 non-null  object \n",
      " 30  Kardes Sayisi                                              63993 non-null  object \n",
      " 31  Girisimcilik Kulupleri Tarzi Bir Kulube Uye misiniz?       63296 non-null  object \n",
      " 32  Uye Oldugunuz Kulubun Ismi                                 16434 non-null  object \n",
      " 33  Profesyonel Bir Spor Daliyla Mesgul musunuz?               64010 non-null  object \n",
      " 34  Spor Dalindaki Rolunuz Nedir?                              32850 non-null  object \n",
      " 35  Aktif olarak bir STK üyesi misiniz?                        52283 non-null  object \n",
      " 36  Hangi STK'nin Uyesisiniz?                                  15607 non-null  object \n",
      " 37  Stk Projesine Katildiniz Mi?                               36817 non-null  object \n",
      " 38  Girisimcilikle Ilgili Deneyiminiz Var Mi?                  52285 non-null  object \n",
      " 39  Girisimcilikle Ilgili Deneyiminizi Aciklayabilir misiniz?  14599 non-null  object \n",
      " 40  Ingilizce Biliyor musunuz?                                 58671 non-null  object \n",
      " 41  Ingilizce Seviyeniz?                                       28592 non-null  object \n",
      " 42  Daha Önceden Mezun Olunduysa, Mezun Olunan Üniversite      419 non-null    object \n",
      " 43  id                                                         65125 non-null  int64  \n",
      "dtypes: float64(2), int64(2), object(40)\n",
      "memory usage: 21.9+ MB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "10461467",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-15T18:15:34.507483Z",
     "iopub.status.busy": "2024-09-15T18:15:34.507129Z",
     "iopub.status.idle": "2024-09-15T18:15:34.711717Z",
     "shell.execute_reply": "2024-09-15T18:15:34.710732Z"
    },
    "papermill": {
     "duration": 0.217235,
     "end_time": "2024-09-15T18:15:34.713854",
     "exception": false,
     "start_time": "2024-09-15T18:15:34.496619",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Basvuru Yili                                                     0\n",
       "Degerlendirme Puani                                              1\n",
       "Cinsiyet                                                       169\n",
       "Dogum Tarihi                                                   177\n",
       "Dogum Yeri                                                     791\n",
       "Ikametgah Sehri                                               2037\n",
       "Universite Adi                                                 132\n",
       "Universite Turu                                                255\n",
       "Burslu ise Burs Yuzdesi                                      42685\n",
       "Burs Aliyor mu?                                                  0\n",
       "Bölüm                                                          231\n",
       "Universite Kacinci Sinif                                       374\n",
       "Universite Not Ortalamasi                                     2753\n",
       "Daha Once Baska Bir Universiteden Mezun Olmus                37345\n",
       "Lise Adi                                                       384\n",
       "Lise Adi Diger                                               60392\n",
       "Lise Sehir                                                    1054\n",
       "Lise Turu                                                      847\n",
       "Lise Bolumu                                                   1009\n",
       "Lise Bolum Diger                                             63599\n",
       "Lise Mezuniyet Notu                                           5917\n",
       "Baska Bir Kurumdan Burs Aliyor mu?                             231\n",
       "Burs Aldigi Baska Kurum                                      43977\n",
       "Baska Kurumdan Aldigi Burs Miktari                           44162\n",
       "Anne Egitim Durumu                                             406\n",
       "Anne Calisma Durumu                                          11896\n",
       "Anne Sektor                                                  34537\n",
       "Baba Egitim Durumu                                            1007\n",
       "Baba Calisma Durumu                                          12618\n",
       "Baba Sektor                                                  20378\n",
       "Kardes Sayisi                                                 1132\n",
       "Girisimcilik Kulupleri Tarzi Bir Kulube Uye misiniz?          1829\n",
       "Uye Oldugunuz Kulubun Ismi                                   48691\n",
       "Profesyonel Bir Spor Daliyla Mesgul musunuz?                  1115\n",
       "Spor Dalindaki Rolunuz Nedir?                                32275\n",
       "Aktif olarak bir STK üyesi misiniz?                          12842\n",
       "Hangi STK'nin Uyesisiniz?                                    49518\n",
       "Stk Projesine Katildiniz Mi?                                 28308\n",
       "Girisimcilikle Ilgili Deneyiminiz Var Mi?                    12840\n",
       "Girisimcilikle Ilgili Deneyiminizi Aciklayabilir misiniz?    50526\n",
       "Ingilizce Biliyor musunuz?                                    6454\n",
       "Ingilizce Seviyeniz?                                         36533\n",
       "Daha Önceden Mezun Olunduysa, Mezun Olunan Üniversite        64706\n",
       "id                                                               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f66644fe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-15T18:15:34.735370Z",
     "iopub.status.busy": "2024-09-15T18:15:34.735040Z",
     "iopub.status.idle": "2024-09-15T18:15:34.740515Z",
     "shell.execute_reply": "2024-09-15T18:15:34.739688Z"
    },
    "papermill": {
     "duration": 0.018179,
     "end_time": "2024-09-15T18:15:34.742335",
     "exception": false,
     "start_time": "2024-09-15T18:15:34.724156",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Config:\n",
    "\n",
    "    catboost_params = {\n",
    "            'random_state': 42,\n",
    "            'loss_function': 'RMSE',\n",
    "            'eval_metric': 'RMSE',\n",
    "            'learning_rate': 0.2,\n",
    "            'iterations': 1000,\n",
    "            'task_type': 'GPU',\n",
    "    }\n",
    "\n",
    "\n",
    "    target_col = 'Degerlendirme Puani'\n",
    "\n",
    "    drop_cols = ['Burslu ise Burs Yuzdesi','Daha Once Baska Bir Universiteden Mezun Olmus', 'Lise Adi Diger',\n",
    "                    'Lise Bolum Diger', 'Uye Oldugunuz Kulubun Ismi', 'Stk Projesine Katildiniz Mi?', 'Ingilizce Seviyeniz?',\n",
    "                    'Daha Önceden Mezun Olunduysa, Mezun Olunan Üniversite']\n",
    "\n",
    "\n",
    "sehir_cols = ['Dogum Yeri', 'Ikametgah Sehri', 'Lise Sehir']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "040b1c20",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-15T18:15:34.763319Z",
     "iopub.status.busy": "2024-09-15T18:15:34.763031Z",
     "iopub.status.idle": "2024-09-15T18:15:50.304781Z",
     "shell.execute_reply": "2024-09-15T18:15:50.303953Z"
    },
    "papermill": {
     "duration": 15.554864,
     "end_time": "2024-09-15T18:15:50.307021",
     "exception": false,
     "start_time": "2024-09-15T18:15:34.752157",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "il_ilce_dict = il_ilce.set_index('ilce')['il'].to_dict()\n",
    "\n",
    "# Function to map Dogum Yeri using the dictionary\n",
    "def map_il_using_dict(dogum_yeri):\n",
    "    for ilce in il_ilce_dict:\n",
    "        if ilce in str(dogum_yeri):\n",
    "            return il_ilce_dict[ilce]\n",
    "    return dogum_yeri\n",
    "\n",
    "def safe_standardize_university_name(name):\n",
    "    if isinstance(name, str):\n",
    "        name = name.upper()\n",
    "        name = re.sub(r'Ü', 'U', name)\n",
    "        name = re.sub(r'İ', 'I', name)\n",
    "        name = re.sub(r'Ö', 'O', name)\n",
    "        name = re.sub(r'Ç', 'C', name)\n",
    "        name = re.sub(r'Ş', 'S', name)\n",
    "        name = re.sub(r'Ğ', 'G', name)\n",
    "        name = re.sub(r'[^A-Z ]', '', name)\n",
    "    return name\n",
    "\n",
    "def safe_standardize_name(name):\n",
    "    if isinstance(name, str):\n",
    "        name = name.upper()\n",
    "        name = re.sub(r'Ü', 'U', name)\n",
    "        name = re.sub(r'İ', 'I', name)\n",
    "        name = re.sub(r'Ö', 'O', name)\n",
    "        name = re.sub(r'Ç', 'C', name)\n",
    "        name = re.sub(r'Ş', 'S', name)\n",
    "        name = re.sub(r'Ğ', 'G', name)\n",
    "        name = re.sub(r'[^A-Z ]', '', name)\n",
    "    return name\n",
    "\n",
    "def group_similar_departments(name):\n",
    "    if isinstance(name, str):\n",
    "\n",
    "        name = re.sub(r'\\s+', '', name.upper())\n",
    "\n",
    "        if 'TIP' in name:\n",
    "            return 'TIP FAKULTESI'\n",
    "        elif 'ISLETME' in name:\n",
    "            return 'ISLETME'\n",
    "        elif 'HUKUK' in name:\n",
    "            return 'HUKUK'\n",
    "        elif 'FIZIK' in name:\n",
    "            return 'FIZIK'\n",
    "        elif 'BILGISAYARMUHENDISLIGI' in name:\n",
    "            return 'BILGISAYAR MUHENDISLIGI'\n",
    "        elif 'ENDUSTRIMUHENDISLIGI' in name:\n",
    "            return 'ENDUSTRI MUHENDISLIGI'\n",
    "        elif 'MAKINEMUHENDISLIGI' in name:\n",
    "            return 'MAKINE MUHENDISLIGI'\n",
    "        elif 'MAKINAMUHENDISLIGI' in name:\n",
    "            return 'MAKINE MUHENDISLIGI'\n",
    "        elif 'GIDAMUHENDISLIGI' in name:\n",
    "            return 'GIDA MUHENDISLIGI'\n",
    "        elif 'MEKATRONIKMUHENDISLIGI' in name:\n",
    "            return 'MEKATRONIK MUHENDISLIGI'\n",
    "        elif 'BIYOMEDIKALMUHENDISLIGI' in name:\n",
    "            return 'BIYOMEDIKAL MUHENDISLIGI'\n",
    "        elif 'ELEKTRIKELEKTRONIKMUHENDISLIGI' in name:\n",
    "            return 'ELEKTRIK ELEKTRONIK MUHENDISLIGI'\n",
    "        elif 'ELEKTRIKMUHENDISLIGI' in name:\n",
    "            return 'ELEKTRIK ELEKTRONIK MUHENDISLIGI'\n",
    "        elif 'ELEKTRONIKMUHENDISLIGI' in name:\n",
    "            return 'ELEKTRIK ELEKTRONIK MUHENDISLIGI'\n",
    "        elif 'ELEKTRONIKHABERLESMEMUHENDISLIGI' in name:\n",
    "            return 'ELEKTRIK ELEKTRONIK MUHENDISLIGI'\n",
    "        elif 'ELEKTRONIKVEHABERLESMEMUHENDISLIGI' in name:\n",
    "            return 'ELEKTRIK ELEKTRONIK MUHENDISLIGI'\n",
    "        elif 'INSAATMUHENDISLIGI' in name:\n",
    "            return 'INSAAT MUHENDISLIGI'\n",
    "        elif 'ICMIMARLIK' in name:\n",
    "            return 'IC MIMARLIK'\n",
    "        elif 'ULUSLARARASIILISKILER' in name:\n",
    "            return 'ULUSLARARASI ILISKILER'\n",
    "        elif 'ENERJIMUHENDISLIGI' in name:\n",
    "            return 'ENERJI MUHENDISLIGI'\n",
    "        elif 'KIMYAMUHENDISLIGI' in name:\n",
    "            return 'KIMYA MUHENDISLIGI'\n",
    "        elif 'IKTISAT' in name:\n",
    "            return 'IKTISAT'\n",
    "        elif 'HARITAMUHENDISLIGI' in name:\n",
    "            return 'HARITA MUHENDISLIGI'\n",
    "        elif 'PSIKOLOJİ' in name:\n",
    "            return 'PSIKOLOJİ'\n",
    "        elif 'HEMSIRELIK'  in name:\n",
    "            return 'HEMSIRELIK'\n",
    "\n",
    "        elif 'MADEN' in name:\n",
    "            return 'MADEN MUHENDISLIGI'\n",
    "        elif 'SOSYOLO' in name:\n",
    "            return 'SOSYOLOJI'\n",
    "        elif 'MALIYE' in name:\n",
    "            return 'MALIYE'\n",
    "        elif 'ILAH' in name:\n",
    "            return 'ILAHIYAT'\n",
    "        elif 'ECZAC' in name:\n",
    "            return 'ECZACILIK'\n",
    "        elif 'DISH' in name:\n",
    "            return 'DIS HEKIMLIGI'\n",
    "        elif 'YONETIMBILIS' in name:\n",
    "            return 'YONETIM BILISIM SISTEMLERI'\n",
    "        elif 'MATEMATIKMU' in name:\n",
    "            return 'MATEMATIK MUHENDISLIGI'\n",
    "        elif 'COGRAFYA' in name:\n",
    "            return 'COGRAFYA'\n",
    "        elif 'GAZETE' in name:\n",
    "            return 'GAZETECILIK'\n",
    "        elif 'FELSEFE' in name:\n",
    "            return 'FELSEFE'\n",
    "        elif 'EDEBIYAT' in name:\n",
    "            return 'EDEBIYAT'\n",
    "\n",
    "        elif 'METALURJI' in name:\n",
    "            return 'METALURJI MALZEME MUHENDISLIGI'\n",
    "        elif 'MALZEME' in name and 'METALURJI' not in name:\n",
    "            return 'MALZEME MUHENDISLIGI'\n",
    "        elif 'SINIFOGRET' in name:\n",
    "            return 'SINIF OGRETMENLIGI'\n",
    "        elif 'CALISMAEKO' in name:\n",
    "            return 'CALISMA EKONOMISI'\n",
    "        elif 'HEMSI' in name:\n",
    "            return 'HEMSIRELIK'\n",
    "        elif 'KAMUY' in name:\n",
    "            return 'KAMU YONETIMI'\n",
    "        elif 'JEOLO' in name:\n",
    "            return 'JEOLOJI MUHENDISLIGI'\n",
    "        elif 'BESLENME' in name:\n",
    "            return 'BESLENME VE DIYETETIK'\n",
    "\n",
    "        elif 'EKONOME' in name:\n",
    "            return 'EKONOMETRI'\n",
    "        elif 'CEVREMU' in name:\n",
    "            return 'CEVRE MUHENDISLIGI'\n",
    "        elif 'YAZILIMMU' in name:\n",
    "            return 'YAZILIM MUHENDISLIGI'\n",
    "        elif 'ENERJISIS' in name:\n",
    "            return 'ENERJI SISTEMLERI MUHENDISLIGI'\n",
    "        elif 'MEKATRONIKMU' in name:\n",
    "            return 'MEKATRONIK MUHENDISLIGI'\n",
    "        elif 'REHBERLIKVE' in name:\n",
    "            return 'REHBERLIK VE PSIKOLOJIK DANISMANLIK'\n",
    "\n",
    "        elif 'OKULON' in name:\n",
    "            return 'OKUL ONCESI OGRETMENLIGI'\n",
    "        elif 'MOLEKU' in name:\n",
    "            return 'MOLEKULER BIYOLOJI VE GENETIK'\n",
    "\n",
    "        elif 'HALKLA' in name:\n",
    "            return 'HALKLA ILISKILER'\n",
    "    return name\n",
    "\n",
    "def group_similar_burs(name):\n",
    "    if isinstance(name, str):\n",
    "\n",
    "        name = re.sub(r'\\s+', '', name.upper())\n",
    "        name = name.strip()\n",
    "\n",
    "        if 'KREDI' in name:\n",
    "            return 'KYK'\n",
    "        elif 'DEVLET' in name:\n",
    "            return 'KYK'\n",
    "        elif 'KREDİ' in name:\n",
    "            return 'KYK'\n",
    "\n",
    "    return name\n",
    "\n",
    "def group_similar_lise(lise):\n",
    "    if isinstance(lise, str):\n",
    "        # Clean and prepare the input string\n",
    "        lise = lise.strip().lower()\n",
    "        lise = re.sub(r'\\s+', '', lise)\n",
    "\n",
    "        # Define categories and their keywords\n",
    "        categories = {\n",
    "            'sayısal': ['sayı', 'sayi', 'fizik', 'fen', 'fm', 'mf'],\n",
    "            'eşit ağırlık': ['esit', 'eşit', 'matematik', 'ea', 'esıt', 'türkçe', 'turkce',\n",
    "                             'eşi̇tağirlik', 'eşi̇t-ağirlik', 'eşi̇tagirlik', 'tmeşi̇tağirlik',\n",
    "                             'meslek-eşi̇tağirlik', 'esi̇tagirlik', 'esi̇tagrlik', 'eşi̇tağirlikbölümü',\n",
    "                             'eşi̇tağirliktm', 'eşi̇tağrlik', 'eş,itağırlık'],\n",
    "            'sözel': ['sözel', 'sosyal', 'ts', 'sozel', 'söz', 'soz'],\n",
    "            'dil bölümü': ['dil', 'ingilizce', 'yabancı', 'yabanci', 'di̇lalani'],\n",
    "            'endüstri meslek lisesi': ['elektrik', 'elektronik', 'bilişim', 'bilgisayar', 'makine',\n",
    "                                       'makina', 'yazilim', 'yazılım', 'veri', 'veritabani', 'endu',\n",
    "                                       'endü', 'otom', 'bi̇li̇şi̇mteknoloji̇leri̇', 'bilisimteknolojileri',\n",
    "                                       'inşaat', 'insaat', 'muhasebe', 'yiyecek', 'icecek', 'içecek', 'turi', 'yi̇yeceki̇çecekhi̇zmetleri̇','konaklama'],\n",
    "            'imam hatip lisesi': ['imamhatip', 'imam hatip lisesi', 'imam'],\n",
    "            'öğretmen': ['öğretmen', 'ogretmen', 'ögretmen'],\n",
    "            'sosyal bilimler': ['sosyaşbilimler', 'soyalbilimler'],\n",
    "            'çocuk gelişimi' : ['çocukgelişimi', 'cocuk', 'gelisim', 'gelişim', 'cocukgelişimi', 'cocukgelisimi'],\n",
    "            'askeri': ['askeri'],\n",
    "        }\n",
    "\n",
    "        # Match the input string with defined categories\n",
    "        for category, keywords in categories.items():\n",
    "            if any(keyword in lise for keyword in keywords):\n",
    "                return category\n",
    "\n",
    "def lda_score(train_df):\n",
    "\n",
    "    turkish_stop_words = [\n",
    "        \"ve\", \"bir\", \"bu\", \"için\", \"ile\", \"de\", \"da\", \"ama\", \"veya\", \"ise\", \"çünkü\", \"ancak\",\n",
    "        \"her\", \"ne\", \"gibi\", \"ki\", \"ya\", \"olarak\", \"çok\", \"olan\", \"daha\", \"değil\", \"kadar\",\n",
    "        \"bile\", \"sonra\", \"birçok\", \"bazı\", \"herkes\", \"biri\", \"birisi\", \"bazıları\", \"bu yüzden\"\n",
    "    ]\n",
    "\n",
    "    # Selecting non-null responses from the column\n",
    "    text_data = train_df['Girisimcilikle Ilgili Deneyiminizi Aciklayabilir misiniz?'].dropna()\n",
    "\n",
    "    # Re-initialize TF-IDF Vectorizer with manually defined Turkish stop words\n",
    "    vectorizer = TfidfVectorizer(stop_words=turkish_stop_words, max_features=1000)\n",
    "    tfidf_matrix = vectorizer.fit_transform(text_data)\n",
    "\n",
    "    # Apply Latent Dirichlet Allocation (LDA) to discover topics within the responses\n",
    "    lda = LatentDirichletAllocation(\n",
    "        n_components=5,\n",
    "        random_state=0,\n",
    "        )\n",
    "    lda.fit(tfidf_matrix)\n",
    "\n",
    "    # Extracting the top words from each topic\n",
    "    n_top_words = 10\n",
    "    feature_names = vectorizer.get_feature_names_out()\n",
    "    topics = {}\n",
    "    for topic_idx, topic in enumerate(lda.components_):\n",
    "        top_features_ind = topic.argsort()[:-n_top_words - 1:-1]\n",
    "        top_features = [feature_names[i] for i in top_features_ind]\n",
    "        topics[f\"Topic {topic_idx+1}\"] = top_features\n",
    "\n",
    "\n",
    "    topic_scores = lda.transform(tfidf_matrix)\n",
    "    non_null_indices = train_df['Girisimcilikle Ilgili Deneyiminizi Aciklayabilir misiniz?'].dropna().index\n",
    "\n",
    "    # Creating a DataFrame from the topic scores and aligning with the original indices\n",
    "    topic_df = pd.DataFrame(lda.transform(tfidf_matrix), index=non_null_indices, columns=[f\"Topic_{i+1}_Score\" for i in range(lda.n_components)])\n",
    "\n",
    "    train_df = train_df.join(topic_df, how='left')\n",
    "\n",
    "    return train_df\n",
    "\n",
    "\n",
    "def girisimcilik_process(train_df):\n",
    "\n",
    "    experience_column = train_df['Girisimcilikle Ilgili Deneyiminizi Aciklayabilir misiniz?'].fillna('')\n",
    "\n",
    "    train_df['character_count'] = experience_column.apply(len)\n",
    "    train_df['word_count'] = experience_column.apply(lambda x: len(x.split()))\n",
    "    train_df['average_word_length'] = train_df['character_count'] / train_df['word_count'].replace(0, 1)\n",
    "\n",
    "    train_df['sentiment'] = experience_column.apply(lambda x: TextBlob(x).sentiment.polarity)\n",
    "\n",
    "    return train_df\n",
    "\n",
    "def stk_process(train_df):\n",
    "\n",
    "    experience_column = train_df[\"Hangi STK'nin Uyesisiniz?\"].fillna('')\n",
    "\n",
    "    train_df['character_count'] = experience_column.apply(len)\n",
    "    train_df['word_count'] = experience_column.apply(lambda x: len(x.split()))\n",
    "    train_df['average_word_length'] = train_df['character_count'] / train_df['word_count'].replace(0, 1)\n",
    "\n",
    "    train_df['sentiment'] = experience_column.apply(lambda x: TextBlob(x).sentiment.polarity)\n",
    "\n",
    "    return train_df\n",
    "\n",
    "\n",
    "train_df['Bölüm'] = train_df['Bölüm'].str.lower().str.strip()\n",
    "test_df['Bölüm'] = test_df['Bölüm'].str.lower().str.strip()\n",
    "\n",
    "reference_list = train_df['Bölüm'].value_counts().index.tolist()\n",
    "reference_list_test = test_df['Bölüm'].value_counts().index.tolist()\n",
    "\n",
    "\n",
    "def standardize_bölüm(value, reference_list):\n",
    "    result = process.extractOne(value, reference_list, scorer=fuzz.partial_ratio)\n",
    "    if result is not None:\n",
    "        match, score, _ = result\n",
    "        if score > 85:\n",
    "            return match\n",
    "    return value\n",
    "\n",
    "train_df['Bölüm'] = train_df['Bölüm'].apply(lambda x: standardize_bölüm(x, reference_list))\n",
    "test_df['Bölüm'] = test_df['Bölüm'].apply(lambda x: standardize_bölüm(x, reference_list_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "015ff46c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-15T18:15:50.329606Z",
     "iopub.status.busy": "2024-09-15T18:15:50.329258Z",
     "iopub.status.idle": "2024-09-15T18:15:50.538339Z",
     "shell.execute_reply": "2024-09-15T18:15:50.537398Z"
    },
    "papermill": {
     "duration": 0.223435,
     "end_time": "2024-09-15T18:15:50.540688",
     "exception": false,
     "start_time": "2024-09-15T18:15:50.317253",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def process_data(df):\n",
    "\n",
    "    global sehir_cols\n",
    "\n",
    "    train_df = df.copy()\n",
    "\n",
    "    train_df = train_df.drop(columns=['id'], errors='ignore')\n",
    "    # train_df = train_df.drop(columns=['Dogum Tarihi'], errors='ignore')\n",
    "\n",
    "    train_df['Dogum Tarihi'] = train_df['Dogum Tarihi'].replace(['1/1/70 2:00'], pd.NaT)\n",
    "    train_df['Dogum Tarihi'] = pd.to_datetime(train_df['Dogum Tarihi'], errors='coerce')\n",
    "    train_df['Dogum Tarihi'] = train_df['Dogum Tarihi'].dt.strftime('%Y-%m-%d')\n",
    "\n",
    "    train_df['Basvuru Tarihi_2'] = pd.to_datetime(train_df['Basvuru Yili'].astype(str) + '-01-01', errors='coerce')\n",
    "    train_df['Age'] = (train_df['Basvuru Tarihi_2'] - pd.to_datetime(train_df['Dogum Tarihi'], errors='coerce')).dt.days // 365\n",
    "\n",
    "    train_df = train_df.drop(columns=['Basvuru Tarihi_2'], errors='ignore')\n",
    "\n",
    "    for col in sehir_cols:\n",
    "        train_df[col] = train_df[col].str.strip().str.title()\n",
    "        train_df[col] = train_df[col].str.split('/').str[0].str.strip()\n",
    "        train_df[col] = train_df[col].str.split(' ').str[0].str.strip()\n",
    "        train_df[col] = train_df[col].str.split('-').str[0].str.strip()\n",
    "        train_df[col] = train_df[col].str.split('_').str[0].str.strip()\n",
    "        train_df[col] = train_df[col].str.split(',').str[0].str.strip()\n",
    "        train_df[col] = train_df[col].replace('İstanbulbakırköy', 'İstanbul')\n",
    "        train_df[col] = train_df[col].replace('Istanbul', 'İstanbul')\n",
    "        train_df[col] = train_df[col].replace('Aliağaizmir', 'İzmir')\n",
    "        train_df[col] = train_df[col].replace('İzmiR', 'İzmir')\n",
    "        train_df[col] = train_df[col].replace('İzmirkonak', 'İzmir')\n",
    "        train_df[col] = train_df[col].replace('Yenimahalleankara', 'Ankara')\n",
    "        train_df[col] = train_df[col].replace('Bursayıldırım', 'Bursa')\n",
    "        train_df[col] = train_df[col].replace('Yumurtalıkadana', 'Adana')\n",
    "        train_df[col] = train_df[col].replace('Karaisalıadana', 'Adana')\n",
    "        train_df[col] = train_df[col].replace('Adanaseyhan', 'Adana')\n",
    "        train_df[col] = train_df[col].replace('Konyaselçuklu', 'Konya')\n",
    "        train_df[col] = train_df[col].replace('Diyarbakir', 'Diyarbakır')\n",
    "        train_df[col] = train_df[col].replace('Diyarbakırdicle', 'Diyarbakır')\n",
    "        train_df[col] = train_df[col].replace('Si̇Lvan ', 'Silvan')\n",
    "        train_df[col] = train_df[col].replace('Sanliurfa', 'Şanlıurfa')\n",
    "        train_df[col] = train_df[col].replace('Şanliurfa', 'Şanlıurfa')\n",
    "        train_df[col] = train_df[col].replace('Ş.Urfa', 'Şanlıurfa')\n",
    "        train_df[col] = train_df[col].replace('Malatyamerkez', 'Malatya')\n",
    "        train_df[col] = train_df[col].replace('Kahramanmaras', 'Kahramanmaraş')\n",
    "        train_df[col] = train_df[col].replace('K.Maras', 'Kahramanmaraş')\n",
    "        train_df[col] = train_df[col].replace('K.Maraş', 'Kahramanmaraş')\n",
    "        train_df[col] = train_df[col].replace('Agri', 'Ağrı')\n",
    "        train_df[col] = train_df[col].replace('Ağri', 'Kahramanmaraş')\n",
    "        train_df[col] = train_df[col].replace('Balikesir', 'Balıkesir')\n",
    "        train_df[col] = train_df[col].replace('BalikesiR', 'Balıkesir')\n",
    "        train_df[col] = train_df[col].replace('Orduünye', 'Ordu')\n",
    "        train_df[col] = train_df[col].replace('Eskisehir', 'Eskişehir')\n",
    "        train_df[col] = train_df[col].replace('Adiyaman', 'Adıyaman')\n",
    "        train_df[col] = train_df[col].replace('Aydin', 'Aydın')\n",
    "        train_df[col] = train_df[col].replace('Bartin', 'Bartın')\n",
    "        train_df[col] = train_df[col].replace('Elazig', 'Elazığ')\n",
    "        train_df[col] = train_df[col].replace('Tekirdag', 'Tekirdağ')\n",
    "        train_df[col] = train_df[col].replace('Sirnak', 'Şırnak')\n",
    "        train_df[col] = train_df[col].replace('Şirnak', 'Şırnak')\n",
    "        train_df[col] = train_df[col].replace('Nigde', 'Niğde')\n",
    "        train_df[col] = train_df[col].replace('Kirikkale', 'Kırıkkale')\n",
    "        train_df[col] = train_df[col].replace('Kirklareli', 'Kırklareli')\n",
    "        train_df[col] = train_df[col].replace('Igdir', 'Iğdır')\n",
    "        train_df[col] = train_df[col].replace('İzmiR', 'İzmir')\n",
    "        train_df[col] = train_df[col].replace('Eflani', 'Karabük')\n",
    "        train_df[col] = train_df[col].replace('Gazipaşa', 'Antalya')\n",
    "        train_df[col] = train_df[col].replace('Gaziemir', 'İzmir')\n",
    "        train_df[col] = train_df[col].replace('Gaziantepnizip', 'Gaziantep')\n",
    "        train_df[col] = train_df[col].replace('Alabama', 'Yurtdışı')\n",
    "        train_df[col] = train_df[col].replace('G.O.Paşa', 'İstanbul')\n",
    "        train_df[col] = train_df[col].replace('Nizip', 'Gaziantep')\n",
    "        train_df[col] = train_df[col].replace('Ni̇ksar', 'Tokat')\n",
    "        train_df[col] = train_df[col].replace('Ni̇lüfer', 'Bursa')\n",
    "        train_df[col] = train_df[col].replace('Nottingham', 'Yurtdışı')\n",
    "        train_df[col] = train_df[col].replace('Naziili', 'Aydın')\n",
    "        train_df[col] = train_df[col].replace('Nusaybi̇n', 'Mardin')\n",
    "        train_df[col] = train_df[col].replace('Ezine', 'Çanakkale')\n",
    "        train_df[col] = train_df[col].replace('Oguzeli', 'Gaziantep')\n",
    "        train_df[col] = train_df[col].replace('Oltu', 'Erzurum')\n",
    "        train_df[col] = train_df[col].replace('Etimesgut', 'Ankara')\n",
    "        train_df[col] = train_df[col].replace('Orhangazi', 'Bursa')\n",
    "        train_df[col] = train_df[col].replace('Orsu', 'Ordu')\n",
    "        train_df[col] = train_df[col].replace('Ortaca', 'Muğla')\n",
    "        train_df[col] = train_df[col].replace('Espi̇ye', 'Giresun')\n",
    "        train_df[col] = train_df[col].replace('Osman', 'Bartın')\n",
    "        train_df[col] = train_df[col].replace('Eskişeir', 'Eskişehir')\n",
    "        train_df[col] = train_df[col].replace('Odunpazarı', 'Eskişehir')\n",
    "        train_df[col] = train_df[col].replace('Narman', 'Erzurum')\n",
    "        train_df[col] = train_df[col].replace('Gazi̇osmanpaşa', 'İstanbul')\n",
    "        train_df[col] = train_df[col].replace('Gediz', 'Kütahya')\n",
    "        train_df[col] = train_df[col].replace('Golcuk', 'Kocaeli')\n",
    "        train_df[col] = train_df[col].replace('Melbourne', 'Yurtdışı')\n",
    "        train_df[col] = train_df[col].replace('Gokcebey', 'Zonguldak')\n",
    "        train_df[col] = train_df[col].replace('Glresun', 'Giresun')\n",
    "        train_df[col] = train_df[col].replace('Meriç', 'Edirne')\n",
    "        train_df[col] = train_df[col].replace('Araç', 'Kastamonu')\n",
    "        train_df[col] = train_df[col].replace('Aladağ', 'Adana')\n",
    "        train_df[col] = train_df[col].replace('Geyve', 'Sakarya')\n",
    "        train_df[col] = train_df[col].replace('Merzi̇fon', 'Amasya')\n",
    "        train_df[col] = train_df[col].replace('Gerger', 'Adıyaman')\n",
    "        train_df[col] = train_df[col].replace('Gercüş.', 'Batman')\n",
    "        train_df[col] = train_df[col].replace('Mi̇las', 'Muğla')\n",
    "        train_df[col] = train_df[col].replace('Mrsin', 'Mersin')\n",
    "        train_df[col] = train_df[col].replace('Gemli̇k', 'Bursa')\n",
    "        train_df[col] = train_df[col].replace('Gemerek', 'Sivas')\n",
    "        train_df[col] = train_df[col].replace('Muradiye', 'Van')\n",
    "        train_df[col] = train_df[col].replace('Muratbey', 'Bursa')\n",
    "        train_df[col] = train_df[col].replace('Gelibolu', 'Çanakkale')\n",
    "        train_df[col] = train_df[col].replace('Mustafa', 'Bursa')\n",
    "        train_df[col] = train_df[col].replace('Mustafakemalpaşa', 'Bursa')\n",
    "        train_df[col] = train_df[col].replace('Gedizkütahya', 'Kütahya')\n",
    "        train_df[col] = train_df[col].replace('Osmancık', 'Çorum')\n",
    "        train_df[col] = train_df[col].replace('Mecitözü', 'Çorum')\n",
    "        train_df[col] = train_df[col].replace('Eskipazar', 'Karabük')\n",
    "        train_df[col] = train_df[col].replace('Erzurun', 'Erzurum')\n",
    "        train_df[col] = train_df[col].replace('Sarıgöl', 'Manisa')\n",
    "        train_df[col] = train_df[col].replace('Sarıkamış', 'Kars')\n",
    "        train_df[col] = train_df[col].replace('Sason', 'Batman')\n",
    "        train_df[col] = train_df[col].replace('Schorndorf', 'Yurtdışı')\n",
    "        train_df[col] = train_df[col].replace('Sehitkamil', 'Gaziantep')\n",
    "        train_df[col] = train_df[col].replace('Selendi', 'Manisa')\n",
    "        train_df[col] = train_df[col].replace('Seli̇m', 'Kars')\n",
    "        train_df[col] = train_df[col].replace('Ekinözü', 'Kahramanmaraş')\n",
    "        train_df[col] = train_df[col].replace('Selçukulu', 'Konya')\n",
    "        train_df[col] = train_df[col].replace('Kandıra', 'Kocaeli')\n",
    "        train_df[col] = train_df[col].replace('Sarikaya', 'Yozgat')\n",
    "        train_df[col] = train_df[col].replace('Edremi̇t', 'Balıkesir')\n",
    "        train_df[col] = train_df[col].replace('Edi̇rne', 'Edirne')\n",
    "        train_df[col] = train_df[col].replace('Arsi̇n', 'Trabzon')\n",
    "        train_df[col] = train_df[col].replace('Ede', 'Giresun')\n",
    "        train_df[col] = train_df[col].replace('Seyi̇tgazi̇', 'Eskişehir')\n",
    "        train_df[col] = train_df[col].apply(map_il_using_dict)\n",
    "\n",
    "        train_df[col] = train_df[col].replace('Karedeniz', 'Trabzon')\n",
    "        train_df[col] = train_df[col].replace('Bartin', 'Bartın')\n",
    "        train_df[col] = train_df[col].replace('Baski̇l', 'Elazığ')\n",
    "        train_df[col] = train_df[col].replace('Elaziğ', 'Elazığ')\n",
    "        train_df[col] = train_df[col].replace('Kktc', 'Kıbrıs')\n",
    "        train_df[col] = train_df[col].replace('Ki̇li̇s', 'Bartın')\n",
    "        train_df[col] = train_df[col].replace('Kiziltepe\t', 'Mardin')\n",
    "        train_df[col] = train_df[col].replace('Kelki̇t', 'Gümüşhane')\n",
    "        train_df[col] = train_df[col].replace('Gümüshane', 'Gümüşhane')\n",
    "        train_df[col] = train_df[col].replace('Gumushane\t', 'Gümüşhane')\n",
    "        train_df[col] = train_df[col].replace('Kdz.', 'Zonguldak')\n",
    "        train_df[col] = train_df[col].replace('Kaçanik', 'Kosova')\n",
    "        train_df[col] = train_df[col].replace('Kazan\t', 'Rusya')\n",
    "        train_df[col] = train_df[col].replace('Kayserı', 'Kayseri')\n",
    "        train_df[col] = train_df[col].replace('Bayindir', 'İzmir')\n",
    "        train_df[col] = train_df[col].replace('Kastamonuci̇de', 'Kastamonu')\n",
    "        train_df[col] = train_df[col].replace('Bağcilar', 'İstanbul')\n",
    "        train_df[col] = train_df[col].replace('Karsıyaka', 'İzmir')\n",
    "        train_df[col] = train_df[col].replace('Berlin', 'Yurtdışı')\n",
    "        train_df[col] = train_df[col].replace('Karadeniz', 'Trabzon')\n",
    "        train_df[col] = train_df[col].replace('Kopnya', 'Konya')\n",
    "        train_df[col] = train_df[col].replace('Kandira', 'Kocaeli')\n",
    "        train_df[col] = train_df[col].replace('Kusadasi', 'Aydın')\n",
    "        train_df[col] = train_df[col].replace('Köln', 'Yurtdışı')\n",
    "        train_df[col] = train_df[col].replace('Aralik', 'Iğdır')\n",
    "        train_df[col] = train_df[col].replace('Arpacay', 'Kars')\n",
    "        train_df[col] = train_df[col].replace('Ni̇ğde', 'Ni̇ğde')\n",
    "        train_df[col] = train_df[col].replace('Avcilar', 'İstanbul')\n",
    "        train_df[col] = train_df[col].replace('Azerbeycan', 'Azerbaycan')\n",
    "        train_df[col] = train_df[col].replace('Meli̇kgazi̇', 'Kayseri')\n",
    "        train_df[col] = train_df[col].replace('Mazidagi', 'Mardin')\n",
    "        train_df[col] = train_df[col].replace('Mardi̇n', 'Mardin')\n",
    "        train_df[col] = train_df[col].replace('Baku', 'Azerbaycan')\n",
    "        train_df[col] = train_df[col].replace('Macoo', 'İran')\n",
    "        train_df[col] = train_df[col].replace('M.K.Paşa', 'Bursa')\n",
    "        train_df[col] = train_df[col].replace('Levent', 'İstanbul')\n",
    "        train_df[col] = train_df[col].replace('Lefkoşe', 'Kıbrıs')\n",
    "        train_df[col] = train_df[col].replace('Lefkoşa', 'Kıbrıs')\n",
    "        train_df[col] = train_df[col].replace('Lazkiye', 'Suriye')\n",
    "        train_df[col] = train_df[col].replace('Bakü', 'Azerbaycan')\n",
    "        train_df[col] = train_df[col].replace('Kırgızistan', 'Kırgızistan')\n",
    "        train_df[col] = train_df[col].replace('Kırcali', 'Bulgaristan')\n",
    "        train_df[col] = train_df[col].replace('Kütahyatavşanlı', 'Kütahya')\n",
    "        train_df[col] = train_df[col].replace('Kâhta', 'Adıyaman')\n",
    "        train_df[col] = train_df[col].replace('Beyşehi̇r', 'Konya')\n",
    "        train_df[col] = train_df[col].replace('Kadıöy', 'İstanbul')\n",
    "        train_df[col] = train_df[col].replace('Kadıkoy', 'İstanbul')\n",
    "        train_df[col] = train_df[col].replace('Erurum', 'Erzurum')\n",
    "        train_df[col] = train_df[col].replace('Erci̇ş', 'Van')\n",
    "        train_df[col] = train_df[col].replace('Emnönü', 'İstanbul')\n",
    "        train_df[col] = train_df[col].replace('Emi̇nönü', 'İstanbul')\n",
    "        train_df[col] = train_df[col].replace('Cankırı', 'Çankırı')\n",
    "        train_df[col] = train_df[col].replace('Cardak', 'Denizli')\n",
    "        train_df[col] = train_df[col].replace('Duzıcı', 'Osmaniye')\n",
    "        train_df[col] = train_df[col].replace('Duisburg', 'Yurtdışı')\n",
    "        train_df[col] = train_df[col].replace('Doğubeyazıt', 'Ağrı')\n",
    "        train_df[col] = train_df[col].replace('Doganhisar', 'Konya')\n",
    "        train_df[col] = train_df[col].replace('Cekerek', 'Yozgat')\n",
    "        train_df[col] = train_df[col].replace('Celikhan', 'Adıyaman')\n",
    "        train_df[col] = train_df[col].replace('Charsadda', 'Pakistan')\n",
    "        train_df[col] = train_df[col].replace('Deri̇k', 'Mardin')\n",
    "        train_df[col] = train_df[col].replace('Ci̇dde', 'Arabistan')\n",
    "        train_df[col] = train_df[col].replace('Demokratik', 'Kongo')\n",
    "        train_df[col] = train_df[col].replace('Dargeçi̇t', 'Mardin')\n",
    "        train_df[col] = train_df[col].replace('D.Bayazıt', 'Ağrı')\n",
    "        train_df[col] = train_df[col].replace('Kemalpasa', 'İzmir')\n",
    "        train_df[col] = train_df[col].replace('Siivas', 'Sivas')\n",
    "        train_df[col] = train_df[col].replace('Ist', 'İstanbul')\n",
    "        train_df[col] = train_df[col].replace('Sisli', 'İstanbul')\n",
    "        train_df[col] = train_df[col].replace('Ispir', 'Erzurum')\n",
    "        train_df[col] = train_df[col].replace('Si̇lvan', 'Diyarbakır')\n",
    "        train_df[col] = train_df[col].replace('Si̇ncan', 'Ankara')\n",
    "        train_df[col] = train_df[col].replace('Iscehisar', 'Afyonkarahisar')\n",
    "        train_df[col] = train_df[col].replace('Afyon', 'Afyonkarahisar')\n",
    "        train_df[col] = train_df[col].replace('Afyonkarahi̇sar', 'Afyonkarahisar')\n",
    "        train_df[col] = train_df[col].replace('Ilgin', 'Konya')\n",
    "        train_df[col] = train_df[col].replace('State', 'Yurtdışı')\n",
    "        train_df[col] = train_df[col].replace('Stockholm', 'Yurtdışı')\n",
    "        train_df[col] = train_df[col].replace('Stuttgart', 'Yurtdışı')\n",
    "        train_df[col] = train_df[col].replace('Altintaş', 'Kütahya')\n",
    "        train_df[col] = train_df[col].replace('Sultanahmet', 'İstanbul')\n",
    "        train_df[col] = train_df[col].replace('Sultandagi', 'Afyonkarahisar')\n",
    "        train_df[col] = train_df[col].replace('Suriye', 'Suriye')\n",
    "        train_df[col] = train_df[col].replace('Suudi', 'Arabistan')\n",
    "        train_df[col] = train_df[col].replace('Sììrt', 'Siirt')\n",
    "        train_df[col] = train_df[col].replace('Sınop', 'Sinop')\n",
    "        train_df[col] = train_df[col].replace('Tacikistan', 'Tacikistan')\n",
    "        train_df[col] = train_df[col].replace('Taksim', 'İstanbul')\n",
    "        train_df[col] = train_df[col].replace('Taksi̇m', 'İstanbul')\n",
    "        train_df[col] = train_df[col].replace('Bi̇ga', 'Çanakkale')\n",
    "        train_df[col] = train_df[col].replace('Tavsanli', 'Kütahya')\n",
    "        train_df[col] = train_df[col].replace('Tavşanli', 'Kütahya')\n",
    "        train_df[col] = train_df[col].replace('Idil', 'Şırnak')\n",
    "        train_df[col] = train_df[col].replace('Ivrindi', 'Balıkesir')\n",
    "        train_df[col] = train_df[col].replace('Seydisehir', 'Konya')\n",
    "        train_df[col] = train_df[col].replace('Ci̇hanbeyli̇', 'Konya')\n",
    "        train_df[col] = train_df[col].replace('Kosova', 'Kosova')\n",
    "        train_df[col] = train_df[col].replace('Barti̇n', 'Bartın')\n",
    "        train_df[col] = train_df[col].replace('Bi̇leci̇k', 'Bi̇leci̇k')\n",
    "        train_df[col] = train_df[col].replace('Kongo', 'Kongo')\n",
    "        train_df[col] = train_df[col].replace('Kiziltepe', 'Mardin')\n",
    "        train_df[col] = train_df[col].replace('Kirklareli̇', 'Kırklareli')\n",
    "        train_df[col] = train_df[col].replace('Bakırkoy', 'İstanbul')\n",
    "        train_df[col] = train_df[col].replace('Kazan', 'Rusya')\n",
    "        train_df[col] = train_df[col].replace('Bol', 'Bolu')\n",
    "        train_df[col] = train_df[col].replace('Bolton', 'Yurtdışı')\n",
    "        train_df[col] = train_df[col].replace('Bratosh', 'Arnavutluk')\n",
    "        train_df[col] = train_df[col].replace('Bristol', 'Yurtdışı')\n",
    "        train_df[col] = train_df[col].replace('Ni̇ğde', 'Ni̇ğde')\n",
    "        train_df[col] = train_df[col].replace('Burhani̇ye', 'Balıkesir')\n",
    "        train_df[col] = train_df[col].replace('Pendi̇k', 'İstanbul')\n",
    "        train_df[col] = train_df[col].replace('K.Çekmece', 'İstanbul')\n",
    "        train_df[col] = train_df[col].replace('Ankar7', 'Ankara')\n",
    "        train_df[col] = train_df[col].replace('Izmr', 'İzmir')\n",
    "        train_df[col] = train_df[col].replace('Sahinbey', 'Gaziantep')\n",
    "        train_df[col] = train_df[col].replace('Altıntş', 'Kütahya')\n",
    "        train_df[col] = train_df[col].replace('Altinözü', 'Hatay')\n",
    "        train_df[col] = train_df[col].replace('Sansun', 'Samsun')\n",
    "        train_df[col] = train_df[col].replace('Tehran', 'İran')\n",
    "        train_df[col] = train_df[col].replace('Hof', 'Almanya')\n",
    "        train_df[col] = train_df[col].replace('Talipli', 'Giresun')\n",
    "        train_df[col] = train_df[col].replace('Tervel', 'Bulgaristan')\n",
    "        train_df[col] = train_df[col].replace('Golkoy', 'Ordu')\n",
    "        train_df[col] = train_df[col].replace('Çamardi', 'Niğde')\n",
    "        train_df[col] = train_df[col].replace('Gleize', 'Yurtdışı')\n",
    "        train_df[col] = train_df[col].replace('Teki̇rdağçorlu', 'Teki̇rdağ')\n",
    "        train_df[col] = train_df[col].replace('Çekirge', 'Bursa')\n",
    "        train_df[col] = train_df[col].replace('Gross', 'Yurtdışı')\n",
    "        train_df[col] = train_df[col].replace('Wuppertal', 'Yurtdışı')\n",
    "        train_df[col] = train_df[col].replace('Viyana', 'Yurtdışı')\n",
    "        train_df[col] = train_df[col].replace('Vezi̇rkörü', 'Samsun')\n",
    "        train_df[col] = train_df[col].replace('Vezi̇rköprü', 'Samsun')\n",
    "        train_df[col] = train_df[col].replace('Vakfikebi̇r', 'Trabzon')\n",
    "        train_df[col] = train_df[col].replace('Ali̇ağa', 'İzmir')\n",
    "        train_df[col] = train_df[col].replace('Ali̇aga', 'İzmir')\n",
    "        train_df[col] = train_df[col].replace('Türkoğu', 'Kahramanmaraş')\n",
    "        train_df[col] = train_df[col].replace('Tunceli̇', 'Tunceli̇')\n",
    "        train_df[col] = train_df[col].replace('Yeni̇ce', 'Çanakkale')\n",
    "        train_df[col] = train_df[col].replace('Trablus', 'Libya')\n",
    "        train_df[col] = train_df[col].replace('Cumhuriyet', 'İstanbul')\n",
    "        train_df[col] = train_df[col].replace('Torbali', 'İzmir')\n",
    "        train_df[col] = train_df[col].replace('Yildirim', 'Bursa')\n",
    "        train_df[col] = train_df[col].replace('?Irıkkale', 'Kırıkkale')\n",
    "        train_df[col] = train_df[col].replace('Göstepe', 'İzmir')\n",
    "        train_df[col] = train_df[col].replace('Gölbaşi', 'Ankara')\n",
    "        train_df[col] = train_df[col].replace('Gıresun', 'Giresun')\n",
    "        train_df[col] = train_df[col].replace('Şahi̇nbey', 'Gaziantep')\n",
    "        train_df[col] = train_df[col].replace('Şanluırfa', 'Şanlıurfa')\n",
    "        train_df[col] = train_df[col].replace('Abington', 'Yurtdışı')\n",
    "        train_df[col] = train_df[col].replace('34239', 'Hatay')\n",
    "        train_df[col] = train_df[col].replace('Üskidar', 'İstanbul')\n",
    "        train_df[col] = train_df[col].replace('Ümrani̇ye', 'İstanbul')\n",
    "        train_df[col] = train_df[col].replace('Şehi̇tkami̇l', 'Gaziantep')\n",
    "        train_df[col] = train_df[col].replace('Şeki̇', 'Azerbaycan')\n",
    "        train_df[col] = train_df[col].replace('İlkadim', 'Samsun')\n",
    "        train_df[col] = train_df[col].replace('Gümüşhaciköy', 'Amasya')\n",
    "        train_df[col] = train_df[col].replace('Çi̇ftli̇k', 'Niğde')\n",
    "        train_df[col] = train_df[col].replace('Çinar', 'Diyarbakır')\n",
    "        train_df[col] = train_df[col].replace('Çeli̇khan', 'Adıyaman')\n",
    "        train_df[col] = train_df[col].replace('Çermi̇k', 'Sivas')\n",
    "        train_df[col] = train_df[col].replace('Akdagmadeni', 'Yozgat')\n",
    "        train_df[col] = train_df[col].replace('Şerefli̇koçhi̇sar', 'Ankara')\n",
    "        train_df[col] = train_df[col].replace('Çankırı', 'Çankırı')\n",
    "        train_df[col] = train_df[col].replace('Ödemi̇ş', 'İzmir')\n",
    "        train_df[col] = train_df[col].replace('Akcadag', 'Malatya')\n",
    "        train_df[col] = train_df[col].replace('Reyhanli', 'Hatay')\n",
    "        train_df[col] = train_df[col].replace('Erzi̇ncan', 'Erzi̇ncan')\n",
    "        train_df[col] = train_df[col].replace('Karşiyaka', 'İzmir')\n",
    "        train_df[col] = train_df[col].replace('Gumushane', 'Gümüşhane')\n",
    "        train_df[col] = train_df[col].replace('Mekke', 'Arabistan')\n",
    "        train_df[col] = train_df[col].replace('Elmali', 'Antalya')\n",
    "        train_df[col] = train_df[col].replace('Kirikhan', 'Hatay')\n",
    "        train_df[col] = train_df[col].replace('Kizilcahamam', 'Ankara')\n",
    "        train_df[col] = train_df[col].replace('Beyoglu', 'İstanbul')\n",
    "        train_df[col] = train_df[col].replace('Bahcelievler', 'İstanbul')\n",
    "        train_df[col] = train_df[col].replace('Osmancik', 'Çorum')\n",
    "        train_df[col] = train_df[col].replace('Eyup', 'İstanbul')\n",
    "        train_df[col] = train_df[col].replace('Hakkari̇', 'Hakkari̇')\n",
    "        train_df[col] = train_df[col].replace('Kahire', 'Mısır')\n",
    "        train_df[col] = train_df[col].replace('Akhi̇sar', 'Manisa')\n",
    "        train_df[col] = train_df[col].replace('G.Antep', 'Gaziantep')\n",
    "        train_df[col] = train_df[col].replace('Alaşehi̇r', 'Manisa')\n",
    "        train_df[col] = train_df[col].replace('Adakli', 'Bingöl')\n",
    "        train_df[col] = train_df[col].replace('Uskudar', 'İstanbul')\n",
    "        train_df[col] = train_df[col].replace('Corum', 'Çorum')\n",
    "        train_df[col] = train_df[col].replace('Karabuk', 'Karabük')\n",
    "        train_df[col] = train_df[col].replace('Fethi̇ye', 'Muğla')\n",
    "        train_df[col] = train_df[col].replace('Sultanbeli', 'İstanbul')\n",
    "        train_df[col] = train_df[col].replace('Kadi̇rli̇', 'Osmaniye')\n",
    "        train_df[col] = train_df[col].replace('Kagithane', 'İstanbul')\n",
    "        train_df[col] = train_df[col].replace('Si̇i̇rt', 'Si̇i̇rt')\n",
    "        train_df[col] = train_df[col].replace('Seydi̇şehi̇r', 'Konya')\n",
    "        train_df[col] = train_df[col].replace('Seri̇k', 'Antalya')\n",
    "        train_df[col] = train_df[col].replace('Artvi̇n', 'Artvi̇n')\n",
    "        train_df[col] = train_df[col].replace('Cankaya', 'Ankara')\n",
    "        train_df[col] = train_df[col].replace('Keçi̇ören', 'Ankara')\n",
    "        train_df[col] = train_df[col].replace('Iğdir', 'Iğdır')\n",
    "        train_df[col] = train_df[col].replace('Iğdir', 'Iğdır')\n",
    "        train_df[col] = train_df[col].replace('Kdz', 'Zonguldak')\n",
    "        train_df[col] = train_df[col].replace('Kağıthane', 'İstanbul')\n",
    "        train_df[col] = train_df[col].replace('Şi̇şli̇', 'İstanbul')\n",
    "        train_df[col] = train_df[col].replace('Bandirma', 'Balıkesir')\n",
    "        train_df[col] = train_df[col].replace('Yüreği̇r', 'Adana')\n",
    "        train_df[col] = train_df[col].replace('Nazi̇lli̇', 'Aydın')\n",
    "        train_df[col] = train_df[col].replace('Altindag', 'Ankara')\n",
    "        train_df[col] = train_df[col].replace('Bi̇tli̇s', 'Bi̇tli̇s')\n",
    "        train_df[col] = train_df[col].replace('Kadikoy', 'İstanbul')\n",
    "        train_df[col] = train_df[col].replace('Kirşehi̇r', 'Kırşehi̇r')\n",
    "        train_df[col] = train_df[col].replace('Inegöl', 'Bursa')\n",
    "        train_df[col] = train_df[col].replace('Kadi̇köy', 'İstanbul')\n",
    "        train_df[col] = train_df[col].replace('Adapazari', 'Sakarya')\n",
    "        train_df[col] = train_df[col].replace('Kutahya', 'Kütahya')\n",
    "        train_df[col] = train_df[col].replace('Eyüp', 'İstanbul')\n",
    "        train_df[col] = train_df[col].replace('Polatli', 'Ankara')\n",
    "        train_df[col] = train_df[col].replace('Kocasi̇nan', 'Kayseri')\n",
    "        train_df[col] = train_df[col].replace('Yeni̇mahalle', 'Ankara')\n",
    "        train_df[col] = train_df[col].replace('Fati̇h', 'İstanbul')\n",
    "        train_df[col] = train_df[col].replace('Balikesi̇r', 'Balıkesi̇r')\n",
    "        train_df[col] = train_df[col].replace('Izmit', 'Kocaeli')\n",
    "        train_df[col] = train_df[col].replace('İzmi̇t', 'Kocaeli')\n",
    "        train_df[col] = train_df[col].replace('Iskenderun', 'Hatay')\n",
    "        train_df[col] = train_df[col].replace('Bakirkoy', 'İstanbul')\n",
    "        train_df[col] = train_df[col].replace('Altindağ', 'Ankara')\n",
    "        train_df[col] = train_df[col].replace('Bakirköy', 'İstanbul')\n",
    "        train_df[col] = train_df[col].replace('Eminönü', 'İstanbul')\n",
    "        train_df[col] = train_df[col].replace('Kadiköy', 'İstanbul')\n",
    "        train_df[col] = train_df[col].replace('Kirsehir', 'Kırşehi̇r')\n",
    "        train_df[col] = train_df[col].replace('Nevsehir', 'Nevşehir')\n",
    "        train_df[col] = train_df[col].replace('Usak', 'Uşak')\n",
    "        train_df[col] = train_df[col].replace('Izmir', 'İzmir')\n",
    "        train_df[col] = train_df[col].replace('Usak', 'Uşak')\n",
    "        train_df[col] = train_df[col].replace('Mugla', 'Muğla')\n",
    "        train_df[col] = train_df[col].replace('Mus', 'Muş')\n",
    "        train_df[col] = train_df[col].replace('Hakkâri', 'Hakkari')\n",
    "        train_df[col] = train_df[col].replace('Di̇yarbakir', 'Di̇yarbakır')\n",
    "        train_df[col] = train_df[col].replace('Girne', 'Kıbrıs')\n",
    "        train_df[col] = train_df[col].replace('Kocamustafapaşa', 'İstanbul')\n",
    "        train_df[col] = train_df[col].replace('İZmir', 'İzmir')\n",
    "        train_df[col] = train_df[col].replace('Feriköy', 'İstanbul')\n",
    "        train_df[col] = train_df[col].replace('Florya', 'İstanbul')\n",
    "        train_df[col] = train_df[col].replace('Gazimağusa', 'Kıbrıs')\n",
    "        train_df[col] = train_df[col].replace('Lefke', 'Kıbrıs')\n",
    "        train_df[col] = train_df[col].replace('Odtü', 'Ankara')\n",
    "        train_df[col] = train_df[col].replace('Oslo', 'Yurtdışı')\n",
    "        train_df[col] = train_df[col].replace('Eryaman', 'Ankara')\n",
    "        train_df[col] = train_df[col].replace('Gazi̇mağusa', 'Kıbrıs')\n",
    "        train_df[col] = train_df[col].replace('Nürnberg', 'Yurtdışı')\n",
    "        train_df[col] = train_df[col].replace('İstanbul\\nNiğde', 'Niğde')\n",
    "        train_df[col] = train_df[col].replace('Çirişhanee', 'Bursa')\n",
    "        train_df[col] = train_df[col].replace('Bilkent', 'Ankara')\n",
    "        train_df[col] = train_df[col].replace('Hacettepe', 'Ankara')\n",
    "        train_df[col] = train_df[col].replace('Yenibosna', 'İstanbul')\n",
    "        train_df[col] = train_df[col].replace('İsparta', 'Isparta')\n",
    "        train_df[col] = train_df[col].replace('Stanbul', 'İstanbul')\n",
    "        train_df[col] = train_df[col].replace('Diger', 'Diğer')\n",
    "        train_df[col] = train_df[col].replace('İsparta', 'Isparta')\n",
    "        train_df[col] = train_df[col].replace('İsparta', 'Isparta')\n",
    "        train_df[col] = train_df[col].replace('İsparta', 'Isparta')\n",
    "        train_df[col] = train_df[col].replace('İsparta', 'Isparta')\n",
    "        train_df[col] = train_df[col].replace('İsparta', 'Isparta')\n",
    "        train_df[col] = train_df[col].replace('İsparta', 'Isparta')\n",
    "        train_df[col] = train_df[col].replace('İsparta', 'Isparta')\n",
    "        train_df[col] = train_df[col].replace('İsparta', 'Isparta')\n",
    "        train_df[col] = train_df[col].replace('İsparta', 'Isparta')\n",
    "        train_df[col] = train_df[col].replace('Mersın', 'Mersin')\n",
    "        train_df[col] = train_df[col].replace('Bilecikbozüyük', 'Bilecik')\n",
    "        train_df[col] = train_df[col].replace('Iznik', 'Bursa')\n",
    "        train_df[col] = train_df[col].replace('Izmır', 'İzmir')\n",
    "        train_df[col] = train_df[col].replace('Istanbu', 'İstanbul')\n",
    "        train_df[col] = train_df[col].replace('Montezuma', 'Diğer')\n",
    "        train_df[col] = train_df[col].replace('Beypazari', 'Ankara')\n",
    "        train_df[col] = train_df[col].replace('Istabul', 'İstanbul')\n",
    "        train_df[col] = train_df[col].replace('Ord', 'Ordu')\n",
    "        train_df[col] = train_df[col].replace('Erenköy', 'İstanbul')\n",
    "        train_df[col] = train_df[col].replace('Beylikduzu', 'İstanbul')\n",
    "        train_df[col] = train_df[col].replace('Peshawar', 'Pakistan')\n",
    "        train_df[col] = train_df[col].replace('Hatay3', 'Hatay')\n",
    "        train_df[col] = train_df[col].replace('Gümüşyaka', 'İstanbul')\n",
    "        train_df[col] = train_df[col].replace('Bakıoğlu', 'Bartın')\n",
    "        train_df[col] = train_df[col].replace('Sarigöl', 'Manisa')\n",
    "        train_df[col] = train_df[col].replace('Seydi̇Kemer', 'Muğla')\n",
    "        train_df[col] = train_df[col].replace('Isranbul', 'İstanbul')\n",
    "        train_df[col] = train_df[col].replace('Kahmanmaraş', 'Kahramanmaraş')\n",
    "        train_df[col] = train_df[col].replace('Kahramanmaas', 'Kahramanmaraş')\n",
    "        train_df[col] = train_df[col].replace('Diyarakır', 'Diyarbakır')\n",
    "        train_df[col] = train_df[col].replace('Kasyeri', 'Kayseri')\n",
    "        train_df[col] = train_df[col].replace('Kinshasa', 'Kongo')\n",
    "        train_df[col] = train_df[col].replace('Kocaei̇', 'Kocaeli̇')\n",
    "        train_df[col] = train_df[col].replace('Cerkezkoy', 'Tekirdağ')\n",
    "        train_df[col] = train_df[col].replace('Kastamony', 'Kastamonu')\n",
    "        train_df[col] = train_df[col].replace('Kolej', 'Diğer')\n",
    "        train_df[col] = train_df[col].replace('Cankiri', 'Çankırı')\n",
    "        train_df[col] = train_df[col].replace('Kurucaşi̇Le', 'Bartın')\n",
    "        train_df[col] = train_df[col].replace('Kuşadasi', 'Aydın')\n",
    "        train_df[col] = train_df[col].replace('Kürkcü', 'Erzurum')\n",
    "        train_df[col] = train_df[col].replace('Canakkale', 'Çanakkale')\n",
    "        train_df[col] = train_df[col].replace('Denizl', 'Denizli')\n",
    "        train_df[col] = train_df[col].replace(':Ankara', 'Ankara')\n",
    "        train_df[col] = train_df[col].replace('Karabbük', 'Karabük')\n",
    "        train_df[col] = train_df[col].replace('Luleburgaz', 'İstanbul')\n",
    "        train_df[col] = train_df[col].replace('Malatua', 'Malatya')\n",
    "        train_df[col] = train_df[col].replace('Bi̇Ngöl', 'Bingöl')\n",
    "        train_df[col] = train_df[col].replace('Kahramanmraş', 'Kahramanmaraş')\n",
    "        train_df[col] = train_df[col].replace('Shirvan', 'Azerbaycan')\n",
    "        train_df[col] = train_df[col].replace('Kdz.Eregli', 'Zonguldak')\n",
    "        train_df[col] = train_df[col].replace('Shkoder', 'Arnavutluk')\n",
    "        train_df[col] = train_df[col].replace('Corly', 'Tekirdağ')\n",
    "        train_df[col] = train_df[col].replace('Ferizaj', 'Kosova')\n",
    "        train_df[col] = train_df[col].replace('Villefranche', 'Yurtdışı')\n",
    "        train_df[col] = train_df[col].replace('Viranşehie', 'Şanlıurfa')\n",
    "        train_df[col] = train_df[col].replace('Duzce', 'Düzce')\n",
    "        train_df[col] = train_df[col].replace('Antaya', 'Antalya')\n",
    "        train_df[col] = train_df[col].replace('Yeşi̇Lköy', 'İstanbul')\n",
    "        train_df[col] = train_df[col].replace('Ankata', 'Ankara')\n",
    "        train_df[col] = train_df[col].replace('Fethıye', 'Muğla')\n",
    "        train_df[col] = train_df[col].replace('Abd', 'Yurtdışı')\n",
    "        train_df[col] = train_df[col].replace('İsyanbul', 'İstanbul')\n",
    "        train_df[col] = train_df[col].replace('Zi̇Le', 'Tokat')\n",
    "        train_df[col] = train_df[col].replace('Ankar', 'Ankara')\n",
    "        train_df[col] = train_df[col].replace('Almanya', 'Yurtdışı')\n",
    "        train_df[col] = train_df[col].replace('Aliaga', 'İzmir')\n",
    "        train_df[col] = train_df[col].replace('İstanbulküçükçekmece', 'İstanbul')\n",
    "        train_df[col] = train_df[col].replace('Alapli', 'Zonguldak')\n",
    "        train_df[col] = train_df[col].replace('Yılmaz', 'Manisa')\n",
    "        train_df[col] = train_df[col].replace('İst', 'İstanbul')\n",
    "        train_df[col] = train_df[col].replace('Urun', 'Uşak')\n",
    "        train_df[col] = train_df[col].replace('Atyrau', 'Kazakistan')\n",
    "        train_df[col] = train_df[col].replace('Şanlıyrfa', 'Şanlıurfa')\n",
    "        train_df[col] = train_df[col].replace('Germncik', 'Aydın')\n",
    "        train_df[col] = train_df[col].replace('Si̇Nopboyabat', 'Si̇nop')\n",
    "        train_df[col] = train_df[col].replace('Gebe', 'Gaziantep')\n",
    "        train_df[col] = train_df[col].replace('Sumgayıt', 'Azerbaycan')\n",
    "        train_df[col] = train_df[col].replace('Ateş', 'Kocaeli')\n",
    "        train_df[col] = train_df[col].replace('Unye', 'Ordu')\n",
    "        train_df[col] = train_df[col].replace('Tekirdağmuratlı', 'Tekirdağ')\n",
    "        train_df[col] = train_df[col].replace('Ti̇Re', 'İzmir')\n",
    "        train_df[col] = train_df[col].replace('Aantalya', 'Antalya')\n",
    "        train_df[col] = train_df[col].replace('Tranzon', 'Trabzon')\n",
    "        train_df[col] = train_df[col].replace('Dıyarbakır', 'Diyarbakır')\n",
    "        train_df[col] = train_df[col].replace('Esme', 'Uşak')\n",
    "        train_df[col] = train_df[col].replace('Tursunzade', 'Tacikistan')\n",
    "        train_df[col] = train_df[col].replace('Gazi̇Paşa', 'Antalya')\n",
    "        train_df[col] = train_df[col].replace('Adi̇Yaman', 'Adıyaman')\n",
    "        train_df[col] = train_df[col].replace('İstabul', 'İstanbul')\n",
    "        train_df[col] = train_df[col].replace('Zakatala', 'Azerbaycan')\n",
    "        train_df[col] = train_df[col].replace('Bi̇Tli̇S', 'Bitlis')\n",
    "        train_df[col] = train_df[col].replace('Artvi̇N', 'Artvi̇n')\n",
    "        train_df[col] = train_df[col].replace('Si̇İRt', 'Si̇irt')\n",
    "        train_df[col] = train_df[col].replace('İstanbuk', 'İstanbul')\n",
    "        train_df[col] = train_df[col].replace('Gi̇Resun', 'Gi̇resun')\n",
    "        train_df[col] = train_df[col].replace('Erzi̇Ncan', 'Erzi̇ncan')\n",
    "        train_df[col] = train_df[col].replace('Ni̇Ğde', 'Ni̇ğde')\n",
    "        train_df[col] = train_df[col].replace('Nevşehi̇R', 'Nevşehi̇r')\n",
    "        train_df[col] = train_df[col].replace('Si̇Nop', 'Si̇nop')\n",
    "        train_df[col] = train_df[col].replace('Bi̇Leci̇K', 'Bi̇leci̇k')\n",
    "        train_df[col] = train_df[col].replace('Si̇Vas', 'Sivas')\n",
    "        train_df[col] = train_df[col].replace('Ri̇Ze', 'Ri̇ze')\n",
    "        train_df[col] = train_df[col].replace('Osmani̇Ye', 'Osmani̇ye')\n",
    "        train_df[col] = train_df[col].replace('Teki̇Rdağ', 'Teki̇rdağ')\n",
    "        train_df[col] = train_df[col].replace('Deni̇Zli̇', 'Deni̇zli̇')\n",
    "        train_df[col] = train_df[col].replace('Eski̇Şehi̇R', 'Eskişehir')\n",
    "        train_df[col] = train_df[col].replace('Di̇Yarbakir', 'Diyarbakır')\n",
    "        train_df[col] = train_df[col].replace('Mani̇Sa', 'Mani̇sa')\n",
    "        train_df[col] = train_df[col].replace('Mersi̇N', 'Mersi̇n')\n",
    "        train_df[col] = train_df[col].replace('Kırşehi̇R', 'Kırşehi̇r')\n",
    "        train_df[col] = train_df[col].replace('İzmi̇R', 'İzmi̇r')\n",
    "\n",
    "\n",
    "    train_df[\"Baba Egitim Durumu\"] = train_df[\"Baba Egitim Durumu\"].replace('İLKOKUL MEZUNU', 'İlkokul')\n",
    "    train_df[\"Baba Egitim Durumu\"] = train_df[\"Baba Egitim Durumu\"].replace('İlkokul Mezunu', 'İlkokul')\n",
    "    train_df[\"Baba Egitim Durumu\"] = train_df[\"Baba Egitim Durumu\"].replace('Eğitimi yok', 'İlkokul')\n",
    "    train_df[\"Baba Egitim Durumu\"] = train_df[\"Baba Egitim Durumu\"].replace('Eğitim Yok', 'İlkokul')\n",
    "    train_df[\"Baba Egitim Durumu\"] = train_df[\"Baba Egitim Durumu\"].replace('EĞİTİM YOK', 'İlkokul')\n",
    "    train_df[\"Baba Egitim Durumu\"] = train_df[\"Baba Egitim Durumu\"].replace('0', 'İlkokul')\n",
    "    train_df[\"Baba Egitim Durumu\"] = train_df[\"Baba Egitim Durumu\"].replace('Ortaokul Mezunu', 'Ortaokul')\n",
    "    train_df[\"Baba Egitim Durumu\"] = train_df[\"Baba Egitim Durumu\"].replace('ORTAOKUL MEZUNU', 'Ortaokul')\n",
    "    train_df[\"Baba Egitim Durumu\"] = train_df[\"Baba Egitim Durumu\"].replace('LİSE', 'Lise')\n",
    "    train_df[\"Baba Egitim Durumu\"] = train_df[\"Baba Egitim Durumu\"].replace('Lise Mezunu', 'Lise')\n",
    "    train_df[\"Baba Egitim Durumu\"] = train_df[\"Baba Egitim Durumu\"].replace('Üniversite Mezunu', 'Üniversite')\n",
    "    train_df[\"Baba Egitim Durumu\"] = train_df[\"Baba Egitim Durumu\"].replace('ÜNİVERSİTE', 'Üniversite')\n",
    "    train_df[\"Baba Egitim Durumu\"] = train_df[\"Baba Egitim Durumu\"].replace('YÜKSEK LİSANS', 'Yüksek Lisans')\n",
    "    train_df[\"Baba Egitim Durumu\"] = train_df[\"Baba Egitim Durumu\"].replace('DOKTORA', 'Doktora')\n",
    "    train_df[\"Baba Egitim Durumu\"] = train_df[\"Baba Egitim Durumu\"].replace('Yüksek Lisans / Doktara', 'Yüksek Lisans / Doktora')\n",
    "\n",
    "\n",
    "\n",
    "    train_df[\"Anne Egitim Durumu\"] = train_df[\"Anne Egitim Durumu\"].replace('İLKOKUL MEZUNU', 'İlkokul')\n",
    "    train_df[\"Anne Egitim Durumu\"] = train_df[\"Anne Egitim Durumu\"].replace('İlkokul Mezunu', 'İlkokul')\n",
    "    train_df[\"Anne Egitim Durumu\"] = train_df[\"Anne Egitim Durumu\"].replace('Eğitimi yok', 'İlkokul')\n",
    "    train_df[\"Anne Egitim Durumu\"] = train_df[\"Anne Egitim Durumu\"].replace('Eğitim Yok', 'İlkokul')\n",
    "    train_df[\"Anne Egitim Durumu\"] = train_df[\"Anne Egitim Durumu\"].replace('EĞİTİM YOK', 'İlkokul')\n",
    "    train_df[\"Anne Egitim Durumu\"] = train_df[\"Anne Egitim Durumu\"].replace('0', 'İlkokul')\n",
    "    train_df[\"Anne Egitim Durumu\"] = train_df[\"Anne Egitim Durumu\"].replace('Ortaokul Mezunu', 'Ortaokul')\n",
    "    train_df[\"Anne Egitim Durumu\"] = train_df[\"Anne Egitim Durumu\"].replace('ORTAOKUL MEZUNU', 'Ortaokul')\n",
    "    train_df[\"Anne Egitim Durumu\"] = train_df[\"Anne Egitim Durumu\"].replace('LİSE', 'Lise')\n",
    "    train_df[\"Anne Egitim Durumu\"] = train_df[\"Anne Egitim Durumu\"].replace('Lise Mezunu', 'Lise')\n",
    "    train_df[\"Anne Egitim Durumu\"] = train_df[\"Anne Egitim Durumu\"].replace('Üniversite Mezunu', 'Üniversite')\n",
    "    train_df[\"Anne Egitim Durumu\"] = train_df[\"Anne Egitim Durumu\"].replace('ÜNİVERSİTE', 'Üniversite')\n",
    "    train_df[\"Anne Egitim Durumu\"] = train_df[\"Anne Egitim Durumu\"].replace('YÜKSEK LİSANS', 'Yüksek Lisans')\n",
    "    train_df[\"Anne Egitim Durumu\"] = train_df[\"Anne Egitim Durumu\"].replace('DOKTORA', 'Doktora')\n",
    "    train_df[\"Anne Egitim Durumu\"] = train_df[\"Anne Egitim Durumu\"].replace('Yüksek Lisans / Doktara', 'Yüksek Lisans / Doktora')\n",
    "\n",
    "\n",
    "    train_df[\"Baba Sektor\"] = train_df[\"Baba Sektor\"].replace('ÖZEL SEKTÖR', 'Özel')\n",
    "    train_df[\"Baba Sektor\"] = train_df[\"Baba Sektor\"].replace('Özel Sektör', 'Özel')\n",
    "    train_df[\"Baba Sektor\"] = train_df[\"Baba Sektor\"].replace('KAMU', 'Kamu')\n",
    "    train_df[\"Baba Sektor\"] = train_df[\"Baba Sektor\"].replace('ÖZEL SEKTÖR', 'Özel')\n",
    "    train_df[\"Baba Sektor\"] = train_df[\"Baba Sektor\"].replace('DİĞER', 'Diğer')\n",
    "\n",
    "    train_df['Spor Dalindaki Rolunuz Nedir?'] = train_df['Spor Dalindaki Rolunuz Nedir?'].replace('Lider/Kaptan', 'Lider')\n",
    "    train_df['Spor Dalindaki Rolunuz Nedir?'] = train_df['Spor Dalindaki Rolunuz Nedir?'].replace('Kaptan', 'Lider')\n",
    "    train_df['Spor Dalindaki Rolunuz Nedir?'] = train_df['Spor Dalindaki Rolunuz Nedir?'].replace('KAPTAN / LİDER', 'Lider')\n",
    "    train_df['Spor Dalindaki Rolunuz Nedir?'] = train_df['Spor Dalindaki Rolunuz Nedir?'].replace('DİĞER', 'Diğer')\n",
    "    train_df['Spor Dalindaki Rolunuz Nedir?'] = train_df['Spor Dalindaki Rolunuz Nedir?'].fillna(\"YOK\")\n",
    "    train_df['Spor Dalindaki Rolunuz Nedir?'] = train_df['Spor Dalindaki Rolunuz Nedir?'].replace('0', 'YOK')\n",
    "\n",
    "\n",
    "    train_df['Kardes Sayisi'] = train_df['Kardes Sayisi'].fillna(0)\n",
    "    train_df['Kardes Sayisi'] = train_df['Kardes Sayisi'].replace('Kardeş Sayısı 1 Ek Bilgi Aile Hk. Anne Vefat', 1)\n",
    "    train_df['Kardes Sayisi'] = train_df['Kardes Sayisi'].astype(int)\n",
    "\n",
    "    train_df[\"Anne Sektor\"] = train_df[\"Anne Sektor\"].replace('ÖZEL SEKTÖR', 'Özel')\n",
    "    train_df[\"Anne Sektor\"] = train_df[\"Anne Sektor\"].replace('Özel Sektör', 'Özel')\n",
    "    train_df[\"Anne Sektor\"] = train_df[\"Anne Sektor\"].replace('KAMU', 'Kamu')\n",
    "    train_df[\"Anne Sektor\"] = train_df[\"Anne Sektor\"].replace('ÖZEL SEKTÖR', 'Özel')\n",
    "    train_df[\"Anne Sektor\"] = train_df[\"Anne Sektor\"].replace('DİĞER', 'Diğer')\n",
    "\n",
    "    train_df['Burs Aldigi Baska Kurum'] = train_df['Burs Aldigi Baska Kurum'].apply(\n",
    "    lambda x: 'KYK' if pd.notna(x) and 'kyk' in x.lower() else x\n",
    "    )\n",
    "\n",
    "    train_df['Burs Aldigi Baska Kurum'] = train_df['Burs Aldigi Baska Kurum'].apply(group_similar_burs)\n",
    "\n",
    "    train_df[\"Burs Aldigi Baska Kurum\"] = train_df[\"Burs Aldigi Baska Kurum\"].replace('Kredi ve Yurtlar Kurumu', 'KYK')\n",
    "    train_df[\"Burs Aldigi Baska Kurum\"] = train_df[\"Burs Aldigi Baska Kurum\"].replace('Kredi Yurtlar Kurumu', 'KYK')\n",
    "    train_df[\"Burs Aldigi Baska Kurum\"] = train_df[\"Burs Aldigi Baska Kurum\"].replace('Kredi yurtlar kurumu', 'KYK')\n",
    "    train_df[\"Burs Aldigi Baska Kurum\"] = train_df[\"Burs Aldigi Baska Kurum\"].replace('Kredi ve yurtlar kurumu', 'KYK')\n",
    "    train_df[\"Burs Aldigi Baska Kurum\"] = train_df[\"Burs Aldigi Baska Kurum\"].replace('K', 'KYK')\n",
    "    train_df[\"Burs Aldigi Baska Kurum\"] = train_df[\"Burs Aldigi Baska Kurum\"].replace('kredi yurtlar kurumu', 'KYK')\n",
    "    train_df[\"Burs Aldigi Baska Kurum\"] = train_df[\"Burs Aldigi Baska Kurum\"].replace('kredi ve yurtlar kurumu', 'KYK')\n",
    "    train_df[\"Burs Aldigi Baska Kurum\"] = train_df[\"Burs Aldigi Baska Kurum\"].replace('Kredi ve yurtlar kurumu', 'KYK')\n",
    "    train_df[\"Burs Aldigi Baska Kurum\"] = train_df[\"Burs Aldigi Baska Kurum\"].replace('KREDİ VE YURTLAR KURUMU', 'KYK')\n",
    "    train_df[\"Burs Aldigi Baska Kurum\"] = train_df[\"Burs Aldigi Baska Kurum\"].replace('Devlet bursu', 'KYK')\n",
    "    train_df[\"Burs Aldigi Baska Kurum\"] = train_df[\"Burs Aldigi Baska Kurum\"].replace('devlet', 'KYK')\n",
    "    train_df[\"Burs Aldigi Baska Kurum\"] = train_df[\"Burs Aldigi Baska Kurum\"].replace('KREDİ YURTLAR KURUMU', 'KYK')\n",
    "    train_df[\"Burs Aldigi Baska Kurum\"] = train_df[\"Burs Aldigi Baska Kurum\"].replace('Kredi ve Yurtlar Genel Müdürlüğü', 'KYK')\n",
    "    train_df[\"Burs Aldigi Baska Kurum\"] = train_df[\"Burs Aldigi Baska Kurum\"].replace('Devlet Bursu', 'KYK')\n",
    "    train_df[\"Burs Aldigi Baska Kurum\"] = train_df[\"Burs Aldigi Baska Kurum\"].replace('DEVLET', 'KYK')\n",
    "    train_df[\"Burs Aldigi Baska Kurum\"] = train_df[\"Burs Aldigi Baska Kurum\"].replace('devlet bursu', 'KYK')\n",
    "    train_df[\"Burs Aldigi Baska Kurum\"] = train_df[\"Burs Aldigi Baska Kurum\"].replace('Kredi', 'KYK')\n",
    "    train_df[\"Burs Aldigi Baska Kurum\"] = train_df[\"Burs Aldigi Baska Kurum\"].replace('KYL', 'KYK')\n",
    "    train_df[\"Burs Aldigi Baska Kurum\"] = train_df[\"Burs Aldigi Baska Kurum\"].replace('KYJ', 'KYK')\n",
    "    train_df[\"Burs Aldigi Baska Kurum\"] = train_df[\"Burs Aldigi Baska Kurum\"].replace('KYM', 'KYK')\n",
    "\n",
    "\n",
    "    train_df['Lise Sehir'] = train_df['Lise Sehir'].str.strip().str.title()\n",
    "    train_df['Lise Sehir'] = train_df['Lise Sehir'].str.split('/').str[0].str.strip()\n",
    "    train_df['Lise Sehir'] = train_df['Lise Sehir'].str.split(' ').str[0].str.strip()\n",
    "    train_df['Lise Sehir'] = train_df['Lise Sehir'].str.split('-').str[0].str.strip()\n",
    "    train_df['Lise Sehir'] = train_df['Lise Sehir'].str.split('_').str[0].str.strip()\n",
    "    train_df['Lise Sehir'] = train_df['Lise Sehir'].str.split(',').str[0].str.strip()\n",
    "\n",
    "    # Perform specific replacements for cities in 'Lise Sehir'\n",
    "    city_replacements = {\n",
    "        'İstanbulbakırköy': 'İstanbul', 'Istanbul': 'İstanbul', 'Aliağaizmir': 'İzmir',\n",
    "        'İzmiR': 'İzmir', 'İzmirkonak': 'İzmir', 'Yenimahalleankara': 'Ankara',\n",
    "        'Bursayıldırım': 'Bursa', 'Yumurtalıkadana': 'Adana', 'Karaisalıadana': 'Adana',\n",
    "        'Adanaseyhan': 'Adana', 'Konyaselçuklu': 'Konya', 'Diyarbakir': 'Diyarbakır',\n",
    "        'Diyarbakırdicle': 'Diyarbakır', 'Si̇Lvan ': 'Silvan', 'Sanliurfa': 'Şanlıurfa',\n",
    "        'Şanliurfa': 'Şanlıurfa', 'Ş.Urfa': 'Şanlıurfa', 'Malatyamerkez': 'Malatya',\n",
    "        'Kahramanmaras': 'Kahramanmaraş', 'K.Maras': 'Kahramanmaraş', 'K.Maraş': 'Kahramanmaraş',\n",
    "        'Agri': 'Ağrı', 'Ağri': 'Kahramanmaraş', 'Balikesir': 'Balıkesir', 'BalikesiR': 'Balıkesir',\n",
    "        'Orduünye': 'Ordu', 'Eskisehir': 'Eskişehir', 'Adiyaman': 'Adıyaman', 'Aydin': 'Aydın',\n",
    "        'Bartin': 'Bartın', 'Elazig': 'Elazığ', 'Tekirdag': 'Tekirdağ', 'Sirnak': 'Şırnak',\n",
    "        'Şirnak': 'Şırnak', 'Nigde': 'Niğde', 'Kirikkale': 'Kırıkkale', 'Kirklareli': 'Kırklareli',\n",
    "        'Igdir': 'Iğdır'\n",
    "    }\n",
    "\n",
    "    train_df['Lise Sehir'] = train_df['Lise Sehir'].replace(city_replacements)\n",
    "\n",
    "    train_df['Universite Kacinci Sinif'] = train_df['Universite Kacinci Sinif'].replace('hazırlık', 'Hazırlık')\n",
    "    train_df[\"Lise Turu\"] = train_df[\"Lise Turu\"].replace('Anadolu Lisesi', 'Anadolu')\n",
    "    train_df[\"Lise Turu\"] = train_df[\"Lise Turu\"].replace('Anadolu lisesi', 'Anadolu')\n",
    "    train_df[\"Lise Turu\"] = train_df[\"Lise Turu\"].replace('Düz lise', 'Düz')\n",
    "    train_df[\"Lise Turu\"] = train_df[\"Lise Turu\"].replace('Düz Lise', 'Düz')\n",
    "\n",
    "    train_df[\"Lise Turu\"] = train_df[\"Lise Turu\"].replace('Özel Lisesi', 'Özel')\n",
    "    train_df[\"Lise Turu\"] = train_df[\"Lise Turu\"].replace('Özel lisesi', 'Özel')\n",
    "    train_df[\"Lise Turu\"] = train_df[\"Lise Turu\"].replace('Özel Lise', 'Özel')\n",
    "\n",
    "    train_df[\"Lise Turu\"] = train_df[\"Lise Turu\"].replace('Meslek lisesi', 'Meslek')\n",
    "    train_df[\"Lise Turu\"] = train_df[\"Lise Turu\"].replace('Meslek Lisesi', 'Meslek')\n",
    "    train_df[\"Lise Turu\"] = train_df[\"Lise Turu\"].replace('Fen lisesi', 'Meslek')\n",
    "    train_df[\"Lise Turu\"] = train_df[\"Lise Turu\"].replace('Fen Lisesi', 'Meslek')\n",
    "\n",
    "    train_df['Cinsiyet'] = train_df['Cinsiyet'].replace('ERKEK', 'Erkek')\n",
    "\n",
    "    train_df['Burs Aliyor mu?'] = train_df['Burs Aliyor mu?'].replace('EVET', 'Evet')\n",
    "    train_df['Burs Aliyor mu?'] = train_df['Burs Aliyor mu?'].replace('evet', 'Evet')\n",
    "    train_df['Burs Aliyor mu?'] = train_df['Burs Aliyor mu?'].replace('hayır', 'Hayır')\n",
    "\n",
    "    train_df['Universite Not Ortalamasi'] = train_df['Universite Not Ortalamasi'].replace('ORTALAMA BULUNMUYOR', 'YOK')\n",
    "    train_df['Universite Not Ortalamasi'] = train_df['Universite Not Ortalamasi'].replace('Not ortalaması yok', 'YOK')\n",
    "    train_df['Universite Not Ortalamasi'] = train_df['Universite Not Ortalamasi'].replace('Ortalama bulunmuyor', 'YOK')\n",
    "    train_df['Universite Not Ortalamasi'] = train_df['Universite Not Ortalamasi'].replace('3.00-2.50', '2.50 - 3.00')\n",
    "    train_df['Universite Not Ortalamasi'] = train_df['Universite Not Ortalamasi'].replace('3.50-3', '3.00 - 3.50')\n",
    "    train_df['Universite Not Ortalamasi'] = train_df['Universite Not Ortalamasi'].replace('3.00 - 3.49', '3.00 - 3.50')\n",
    "    train_df['Universite Not Ortalamasi'] = train_df['Universite Not Ortalamasi'].replace('2.50 -3.00', '2.50 - 3.00')\n",
    "    train_df['Universite Not Ortalamasi'] = train_df['Universite Not Ortalamasi'].replace('2.50 - 2.99', '2.50 - 3.00')\n",
    "    train_df['Universite Not Ortalamasi'] = train_df['Universite Not Ortalamasi'].replace('4-3.5', '3.50 - 4.00')\n",
    "    train_df['Universite Not Ortalamasi'] = train_df['Universite Not Ortalamasi'].replace('4.0-3.5', '3.50 - 4.00')\n",
    "\n",
    "    train_df['Universite Turu'] = train_df['Universite Turu'].replace('Devlet', 'DEVLET')\n",
    "    train_df['Universite Turu'] = train_df['Universite Turu'].replace('Özel', 'ÖZEL')\n",
    "\n",
    "    train_df['Lise Bolumu'] = train_df['Lise Bolumu'].apply(group_similar_lise)\n",
    "\n",
    "\n",
    "    train_df['Bölüm'] = train_df['Bölüm'].apply(safe_standardize_name)\n",
    "    train_df['Universite Adi'] = train_df['Universite Adi'].apply(safe_standardize_university_name)\n",
    "    train_df['Bölüm'] = train_df['Bölüm'].apply(group_similar_departments)\n",
    "\n",
    "\n",
    "    train_df['Bölüm'] = train_df['Bölüm'].replace('BILGISAYARBILIMIVEMUHENDISLIGI', 'BILGISAYAR MUHENDISLIĞI')\n",
    "    train_df['Bölüm'] = train_df['Bölüm'].replace('BILGISAYARMUHENDISLIG', 'BILGISAYAR MUHENDISLIĞI')\n",
    "    train_df['Bölüm'] = train_df['Bölüm'].replace('BILGISAYARMUH', 'BILGISAYAR MUHENDISLIĞI')\n",
    "    train_df['Bölüm'] = train_df['Bölüm'].replace('BILGISAYARMUHENDISLI', 'BILGISAYAR MUHENDISLIĞI')\n",
    "    train_df['Bölüm'] = train_df['Bölüm'].replace('BILGISAYARVEYAZILIMMUHENDISLIGI', 'BILGISAYAR MUHENDISLIĞI')\n",
    "    train_df['Bölüm'] = train_df['Bölüm'].replace('BILGISAYARMUHENDISI', 'BILGISAYAR MUHENDISLIĞI')\n",
    "    train_df['Bölüm'] = train_df['Bölüm'].replace('BILGISAYARMUHENDISL', 'BILGISAYAR MUHENDISLIĞI')\n",
    "    train_df['Bölüm'] = train_df['Bölüm'].replace('BILGISAYARM', 'BILGISAYAR MUHENDISLIĞI')\n",
    "    train_df['Bölüm'] = train_df['Bölüm'].replace('BILGISAYARMUHENDI', 'BILGISAYAR MUHENDISLIĞI')\n",
    "    train_df['Bölüm'] = train_df['Bölüm'].replace('YONETIMBILISIMSISTEMLERIBILGISAYARMUHILEDEYANDALYAPIYORUM', 'BILGISAYAR MUHENDISLIĞI')\n",
    "    train_df['Bölüm'] = train_df['Bölüm'].replace('LISANSBILGISAYARMUHYLISANSELEKTRIKELEKTRONIKMUH', 'BILGISAYAR MUHENDISLIĞI')\n",
    "    train_df['Bölüm'] = train_df['Bölüm'].replace('BILGISAYARSISTEMLERIVEMUHENDI', 'BILGISAYAR MUHENDISLIĞI')\n",
    "    train_df['Bölüm'] = train_df['Bölüm'].replace('BILGISAYARMUHENG', 'BILGISAYAR MUHENDISLIĞI')\n",
    "    train_df['Bölüm'] = train_df['Bölüm'].replace('BILGISAYARMUHENDISLIG', 'BILGISAYAR MUHENDISLIĞI')\n",
    "    train_df['Bölüm'] = train_df['Bölüm'].replace('BILGISAYARMUHNEDISLIGI', 'BILGISAYAR MUHENDISLIĞI')\n",
    "    train_df['Bölüm'] = train_df['Bölüm'].replace('BILGISAYARMUHINGILIZCE', 'BILGISAYAR MUHENDISLIĞI')\n",
    "    train_df['Bölüm'] = train_df['Bölüm'].replace('BILGISAYARMUHING', 'BILGISAYAR MUHENDISLIĞI')\n",
    "    train_df['Bölüm'] = train_df['Bölüm'].replace('BILGISAYARMUHENSILIGI', 'BILGISAYAR MUHENDISLIĞI')\n",
    "    train_df['Bölüm'] = train_df['Bölüm'].replace('BILGISAYARELEKTRIKELEKTRONIKMUHENDISLIGI', 'BILGISAYAR MUHENDISLIĞI')\n",
    "    train_df['Bölüm'] = train_df['Bölüm'].replace('BILGISAYARMUHE', 'BILGISAYAR MUHENDISLIĞI')\n",
    "    train_df['Bölüm'] = train_df['Bölüm'].replace('BILGISAYARMUHENDIS', 'BILGISAYAR MUHENDISLIĞI')\n",
    "    train_df['Bölüm'] = train_df['Bölüm'].replace('BILGISAYARMUHENDILS', 'BILGISAYAR MUHENDISLIĞI')\n",
    "    train_df['Bölüm'] = train_df['Bölüm'].replace('BILGISAYARMUHENDILIGI', 'BILGISAYAR MUHENDISLIĞI')\n",
    "    train_df['Bölüm'] = train_df['Bölüm'].replace('BILGISAYARMUHEN', 'BILGISAYAR MUHENDISLIĞI')\n",
    "    train_df['Bölüm'] = train_df['Bölüm'].replace('BILGISAYARMU', 'BILGISAYAR MUHENDISLIĞI')\n",
    "    train_df['Bölüm'] = train_df['Bölüm'].replace('BILGISAYARMGHEN', 'BILGISAYAR MUHENDISLIĞI')\n",
    "    train_df['Bölüm'] = train_df['Bölüm'].replace('BILGISAYARVEBILISIMMUHENDISLIGI', 'BILGISAYAR MUHENDISLIĞI')\n",
    "    train_df['Bölüm'] = train_df['Bölüm'].replace('BILGISAYAR MUHENDISLIĞI', 'BILGISAYAR MUHENDISLIĞI')\n",
    "\n",
    "\n",
    "\n",
    "    train_df['Bölüm'] = train_df['Bölüm'].replace('MIMARLIKINGILIZCE', 'MIMARLIK')\n",
    "    train_df['Bölüm'] = train_df['Bölüm'].replace('MIMARLIKBURSLU', 'MIMARLIK')\n",
    "    train_df['Bölüm'] = train_df['Bölüm'].replace('MIMARLIKINGILIZCETAMBURSLU')\n",
    "    train_df['Bölüm'] = train_df['Bölüm'].replace('MIMARLIKBOLUMU', 'MIMARLIK')\n",
    "    train_df['Bölüm'] = train_df['Bölüm'].replace('MIMARLIKTAMBURSLU', 'MIMARLIK')\n",
    "    train_df['Bölüm'] = train_df['Bölüm'].replace('MIMARLIKINGILIZCEBURSLU', 'MIMARLIK')\n",
    "    train_df['Bölüm'] = train_df['Bölüm'].replace('MIMARLIKCIFTANADALPROGRAMIOGRENCISIYIMMIMARLIKEGITIMIMITAMAMLADIMINSAATMUHENDISLIGIEGITIMIMISURDURUYORUM', 'MIMARLIK')\n",
    "    train_df['Bölüm'] = train_df['Bölüm'].replace('MIMARLIKCIFTANADALPROGRAMI', 'MIMARLIK')\n",
    "    train_df['Bölüm'] = train_df['Bölüm'].replace('MIMARLIKFAKU', 'MIMARLIK')\n",
    "    train_df['Bölüm'] = train_df['Bölüm'].replace('MIMARLIKFAKULTESI', 'MIMARLIK')\n",
    "    train_df['Bölüm'] = train_df['Bölüm'].replace('MIMARLIKFAKULTESIMIMARLIK', 'MIMARLIK')\n",
    "    train_df['Bölüm'] = train_df['Bölüm'].replace('MIMARLIKFAKULTESIYUKSEKLISANS', 'MIMARLIK')\n",
    "    train_df['Bölüm'] = train_df['Bölüm'].replace('MIMARLIKHAYALLERIMINMESLEGIDESEKDAHADOGRUOLUR', 'MIMARLIK')\n",
    "    train_df['Bölüm'] = train_df['Bölüm'].replace('MIMARLIKING', 'MIMARLIK')\n",
    "    train_df['Bölüm'] = train_df['Bölüm'].replace('MIMARLIKOKUYORUMSADECE', 'MIMARLIK')\n",
    "    train_df['Bölüm'] = train_df['Bölüm'].replace('MIMARLIKVEICMIMARLIKCIFTANADAL', 'MIMARLIK')\n",
    "    train_df['Bölüm'] = train_df['Bölüm'].replace('MIMARLIKYUKSEKLISAN', 'MIMARLIK')\n",
    "    train_df['Bölüm'] = train_df['Bölüm'].replace('MUHENDISLIKVEMIMARLIKFAKULTESIMIMARLIK', 'MIMARLIK')\n",
    "    train_df['Bölüm'] = train_df['Bölüm'].replace('INGILIZCEMIMARLIK', 'MIMARLIK')\n",
    "    train_df['Bölüm'] = train_df['Bölüm'].replace('MIMARLI', 'MIMARLIK')\n",
    "    train_df['Bölüm'] = train_df['Bölüm'].replace('MIMARL', 'MIMARLIK')\n",
    "    train_df['Bölüm'] = train_df['Bölüm'].replace('MIMARLIKB', 'MIMARLIK')\n",
    "    train_df['Bölüm'] = train_df['Bölüm'].replace('MIMARLIKCIFTANADALPROGRAMI', 'MIMARLIK')\n",
    "\n",
    "\n",
    "    # train_df['ANNE_BABA_EGITIM'] = train_df['Anne Egitim Durumu'].astype(str) + '_' + train_df['Baba Egitim Durumu'].astype(str)\n",
    "\n",
    "\n",
    "    train_df = lda_score(train_df)\n",
    "    train_df = girisimcilik_process(train_df)\n",
    "\n",
    "    # train_df = stk_process(train_df)\n",
    "\n",
    "    # train_df = lda_score_2(train_df)\n",
    "    # train_df = ngram_process(train_df)\n",
    "    # train_df = ner_process(train_df)\n",
    "    # train_df = apply_tfidf(train_df)\n",
    "\n",
    "    return train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "65e0f1d1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-15T18:15:50.562445Z",
     "iopub.status.busy": "2024-09-15T18:15:50.562097Z",
     "iopub.status.idle": "2024-09-15T18:17:39.925208Z",
     "shell.execute_reply": "2024-09-15T18:17:39.924396Z"
    },
    "papermill": {
     "duration": 109.37666,
     "end_time": "2024-09-15T18:17:39.927638",
     "exception": false,
     "start_time": "2024-09-15T18:15:50.550978",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df[Config.target_col].fillna(0, inplace=True)\n",
    "\n",
    "train_df = process_data(train_df)\n",
    "test_df = process_data(test_df)\n",
    "\n",
    "train_df = train_df.drop(columns=Config.drop_cols)\n",
    "test_df = test_df.drop(columns=Config.drop_cols)\n",
    "\n",
    "\n",
    "cat_cols_train= train_df.select_dtypes(include=['object']).columns\n",
    "cat_cols_test = test_df.select_dtypes(include=['object']).columns\n",
    "\n",
    "for col in cat_cols_train:\n",
    "    train_df[col] = train_df[col].astype(str).fillna('Missing')\n",
    "    train_df[col] = train_df[col].astype('category')\n",
    "\n",
    "\n",
    "for col in cat_cols_test:\n",
    "    test_df[col] = test_df[col].astype(str).fillna('Missing')\n",
    "    test_df[col] = test_df[col].astype('category')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2bedefa3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-15T18:17:39.949403Z",
     "iopub.status.busy": "2024-09-15T18:17:39.949040Z",
     "iopub.status.idle": "2024-09-15T18:17:39.956290Z",
     "shell.execute_reply": "2024-09-15T18:17:39.955458Z"
    },
    "papermill": {
     "duration": 0.020231,
     "end_time": "2024-09-15T18:17:39.958283",
     "exception": false,
     "start_time": "2024-09-15T18:17:39.938052",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_df['Lise Bolumu'].value_counts())\n",
    "# 360"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cbb451de",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-15T18:17:39.979948Z",
     "iopub.status.busy": "2024-09-15T18:17:39.979642Z",
     "iopub.status.idle": "2024-09-15T18:17:39.987715Z",
     "shell.execute_reply": "2024-09-15T18:17:39.986854Z"
    },
    "papermill": {
     "duration": 0.020654,
     "end_time": "2024-09-15T18:17:39.989614",
     "exception": false,
     "start_time": "2024-09-15T18:17:39.968960",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lise Bolumu\n",
       "sayısal                   35090\n",
       "eşit ağırlık              20944\n",
       "sözel                      4228\n",
       "None                       2853\n",
       "dil bölümü                 1517\n",
       "endüstri meslek lisesi      454\n",
       "çocuk gelişimi               26\n",
       "öğretmen                      5\n",
       "imam hatip lisesi             4\n",
       "askeri                        2\n",
       "sosyal bilimler               2\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['Lise Bolumu'].value_counts()\n",
    "# 34459"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5fe3de86",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-15T18:17:40.011198Z",
     "iopub.status.busy": "2024-09-15T18:17:40.010554Z",
     "iopub.status.idle": "2024-09-15T18:17:40.017257Z",
     "shell.execute_reply": "2024-09-15T18:17:40.016075Z"
    },
    "papermill": {
     "duration": 0.020076,
     "end_time": "2024-09-15T18:17:40.019758",
     "exception": false,
     "start_time": "2024-09-15T18:17:39.999682",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def full_fit_cb(data, target_col):\n",
    "    X = data.drop(target_col, axis=1)\n",
    "    y = data[target_col]\n",
    "\n",
    "    cat_features = [X.columns.get_loc(col) for col in X.select_dtypes(include=['category'])]\n",
    "\n",
    "    print(\"Training model on full dataset...\")\n",
    "    model = cb.CatBoostRegressor(**Config.catboost_params)\n",
    "\n",
    "    model.fit(X, y,\n",
    "                cat_features=cat_features,\n",
    "                verbose=100)\n",
    "\n",
    "    print(\"Training completed.\")\n",
    "\n",
    "    # If you want to calculate training RMSE\n",
    "    train_preds = model.predict(X)\n",
    "    train_rmse = sqrt(mean_squared_error(y, train_preds))\n",
    "    print(f'Training RMSE: {train_rmse:.4f}')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7754cb91",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-15T18:17:40.041443Z",
     "iopub.status.busy": "2024-09-15T18:17:40.041033Z",
     "iopub.status.idle": "2024-09-15T18:17:40.050956Z",
     "shell.execute_reply": "2024-09-15T18:17:40.050089Z"
    },
    "papermill": {
     "duration": 0.022699,
     "end_time": "2024-09-15T18:17:40.052835",
     "exception": false,
     "start_time": "2024-09-15T18:17:40.030136",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_catboost(data, target_col):\n",
    "    \n",
    "    X = data.drop(target_col, axis=1)\n",
    "    y = data[target_col]\n",
    "        \n",
    "    cv = KFold(n_splits=5, random_state=42, shuffle=True)\n",
    "    models = []\n",
    "    oof_preds = np.zeros(X.shape[0])\n",
    "    metrics = []\n",
    "    \n",
    "    cat_features = [X.columns.get_loc(col) for col in X.select_dtypes(include=['category'])]\n",
    "    \n",
    "    for fi, (train_idx, valid_idx) in enumerate(cv.split(X, y)):\n",
    "        \n",
    "        print(f'Fold {fi+1}/{5} ...')\n",
    "        \n",
    "        model = cb.CatBoostRegressor(**Config.catboost_params)\n",
    "        \n",
    "        model.fit(X.iloc[train_idx], y.iloc[train_idx],\n",
    "                  eval_set=(X.iloc[valid_idx], y.iloc[valid_idx]),\n",
    "                  use_best_model=True,\n",
    "#                   early_stopping_rounds=Config.early_stop,\n",
    "                  cat_features = cat_features,\n",
    "                  verbose=100)\n",
    "        \n",
    "        preds = model.predict(X.iloc[valid_idx])\n",
    "        \n",
    "        oof_preds[valid_idx] = preds\n",
    "        \n",
    "        \n",
    "        rmse = sqrt(mean_squared_error(y.iloc[valid_idx], preds))\n",
    "        metrics.append(rmse)\n",
    "        print(f'Fold {fi+1} RMSE: {rmse:.4f}')\n",
    "        \n",
    "        models.append(model)\n",
    "        \n",
    "        \n",
    "    oof_rmse = sqrt(mean_squared_error(y, oof_preds))\n",
    "    \n",
    "    print(f'Average RMSE: {np.mean(metrics):.4f}')\n",
    "    print(f'OOF RMSE: {oof_rmse:.4f}')\n",
    "    \n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f1a5dfb5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-15T18:17:40.074518Z",
     "iopub.status.busy": "2024-09-15T18:17:40.073948Z",
     "iopub.status.idle": "2024-09-15T18:17:40.079396Z",
     "shell.execute_reply": "2024-09-15T18:17:40.078557Z"
    },
    "papermill": {
     "duration": 0.01841,
     "end_time": "2024-09-15T18:17:40.081198",
     "exception": false,
     "start_time": "2024-09-15T18:17:40.062788",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def infer_models(data, catboost_models):\n",
    "    \n",
    "#     xgb_data = data.copy()\n",
    "#     dxgb = xgb.DMatrix(xgb_data, enable_categorical=True)\n",
    "    # Ensure the predictions are not empty\n",
    "    catboost_preds = np.mean([model.predict(data) for model in catboost_models], axis=0)\n",
    "#     lightgbm_preds = np.mean([model.predict(data) for model in lightgbm_models], axis=0)\n",
    "#     xgboost_preds = np.mean([model.predict(dxgb) for model in xgboost_models], axis=0)\n",
    "    # combined_preds = (catboost_preds + lightgbm_preds + xgboost_preds) / 3\n",
    "    combined_preds = catboost_preds\n",
    "    \n",
    "    # Debug: Check length of predictions\n",
    "    print(f'Predictions length: {len(combined_preds)}')  # Ensure this matches the length of data\n",
    "    \n",
    "    return combined_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "13543a2d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-15T18:17:40.102730Z",
     "iopub.status.busy": "2024-09-15T18:17:40.102027Z",
     "iopub.status.idle": "2024-09-15T18:17:40.106994Z",
     "shell.execute_reply": "2024-09-15T18:17:40.106142Z"
    },
    "papermill": {
     "duration": 0.017481,
     "end_time": "2024-09-15T18:17:40.108794",
     "exception": false,
     "start_time": "2024-09-15T18:17:40.091313",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def full_fit_infer(data, target_col, catboost_model):\n",
    "  # Ensure we're using the correct columns\n",
    "    X = data.drop(target_col, axis=1) if target_col in data.columns else data\n",
    "\n",
    "      # Make predictions using the full model\n",
    "    predictions = catboost_model.predict(X)\n",
    "\n",
    "      # Debug: Check length of predictions\n",
    "    print(f'Predictions length: {len(predictions)}')  # Ensure this matches the length of data\n",
    "\n",
    "    return predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5dd5cf43",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-15T18:17:40.130151Z",
     "iopub.status.busy": "2024-09-15T18:17:40.129597Z",
     "iopub.status.idle": "2024-09-15T18:17:40.134521Z",
     "shell.execute_reply": "2024-09-15T18:17:40.133657Z"
    },
    "papermill": {
     "duration": 0.017756,
     "end_time": "2024-09-15T18:17:40.136502",
     "exception": false,
     "start_time": "2024-09-15T18:17:40.118746",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of CPU cores: 4\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Get the number of CPU cores\n",
    "num_cores = os.cpu_count()\n",
    "print(f\"Number of CPU cores: {num_cores}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "39edba99",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-15T18:17:40.158538Z",
     "iopub.status.busy": "2024-09-15T18:17:40.158009Z",
     "iopub.status.idle": "2024-09-15T18:17:40.161682Z",
     "shell.execute_reply": "2024-09-15T18:17:40.160848Z"
    },
    "papermill": {
     "duration": 0.016616,
     "end_time": "2024-09-15T18:17:40.163614",
     "exception": false,
     "start_time": "2024-09-15T18:17:40.146998",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model = train_catboost(train_df, Config.target_col)\n",
    "# predictions = infer_models(test_df, Config.target_col, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c6d03e9a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-15T18:17:40.184957Z",
     "iopub.status.busy": "2024-09-15T18:17:40.184675Z",
     "iopub.status.idle": "2024-09-15T19:04:52.546010Z",
     "shell.execute_reply": "2024-09-15T19:04:52.545150Z"
    },
    "papermill": {
     "duration": 2832.374223,
     "end_time": "2024-09-15T19:04:52.547995",
     "exception": false,
     "start_time": "2024-09-15T18:17:40.173772",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20240915_181740\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.1.1\n",
      "Python Version:     3.10.14\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Thu Jun 27 20:43:36 UTC 2024\n",
      "CPU Count:          4\n",
      "Memory Avail:       29.74 GB / 31.36 GB (94.9%)\n",
      "Disk Space Avail:   19.50 GB / 19.52 GB (99.9%)\n",
      "===================================================\n",
      "Presets specified: ['medium_quality']\n",
      "Beginning AutoGluon training ... Time limit = 57600s\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20240915_181740\"\n",
      "Train Data Rows:    65125\n",
      "Train Data Columns: 44\n",
      "Label Column:       Degerlendirme Puani\n",
      "Problem Type:       regression\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    30481.98 MB\n",
      "\tTrain Data (Original)  Memory Usage: 25.22 MB (0.1% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('category', []) : 32 | ['Cinsiyet', 'Dogum Tarihi', 'Dogum Yeri', 'Ikametgah Sehri', 'Universite Adi', ...]\n",
      "\t\t('float', [])    :  8 | ['Age', 'Topic_1_Score', 'Topic_2_Score', 'Topic_3_Score', 'Topic_4_Score', ...]\n",
      "\t\t('int', [])      :  4 | ['Basvuru Yili', 'Kardes Sayisi', 'character_count', 'word_count']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])  : 31 | ['Cinsiyet', 'Dogum Tarihi', 'Dogum Yeri', 'Ikametgah Sehri', 'Universite Adi', ...]\n",
      "\t\t('float', [])     :  8 | ['Age', 'Topic_1_Score', 'Topic_2_Score', 'Topic_3_Score', 'Topic_4_Score', ...]\n",
      "\t\t('int', [])       :  4 | ['Basvuru Yili', 'Kardes Sayisi', 'character_count', 'word_count']\n",
      "\t\t('int', ['bool']) :  1 | ['Burs Aliyor mu?']\n",
      "\t0.4s = Fit runtime\n",
      "\t44 features in original data used to generate 44 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 8.40 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.4s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (20 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'GBM': [{'max_depth': 6, 'device': 'cpu'}, {'max_depth': 5, 'device': 'cpu'}, {'max_depth': 4, 'device': 'cpu'}],\n",
      "\t'XGB': [{'max_depth': 6}, {'max_depth': 5}, {'max_depth': 4}],\n",
      "\t'CAT': [{'depth': 6}, {'depth': 5}, {'depth': 4}],\n",
      "\t'RF': [{'max_depth': 6}, {'max_depth': 5}, {'max_depth': 4}],\n",
      "\t'XT': [{'max_depth': 6}, {'max_depth': 5}, {'max_depth': 4}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Included models: ['CAT', 'XGB', 'GBM', 'RF', 'XT'] (Specified by `included_model_types`, all other model types will be skipped)\n",
      "Fitting 20 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 38390.13s of the 57599.59s of remaining time.\n",
      "2024-09-15 18:17:41,615\tINFO util.py:124 -- Outdated packages:\n",
      "  ipywidgets==7.7.1 found, needs ipywidgets>=8\n",
      "Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n",
      "Will use sequential fold fitting strategy because import of ray failed. Reason: ray==2.24.0 detected. 2.10.0 <= ray < 2.11.0 is required. You can use pip to install certain version of ray `pip install ray==2.10.0` \n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-6.4441\t = Validation score   (-root_mean_squared_error)\n",
      "\t19.72s\t = Training   runtime\n",
      "\t1.15s\t = Validation runtime\n",
      "Fitting model: LightGBM_2_BAG_L1 ... Training model for up to 38368.3s of the 57577.77s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-6.4744\t = Validation score   (-root_mean_squared_error)\n",
      "\t22.17s\t = Training   runtime\n",
      "\t1.4s\t = Validation runtime\n",
      "Fitting model: LightGBM_3_BAG_L1 ... Training model for up to 38344.33s of the 57553.79s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with SequentialLocalFoldFittingStrategy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's rmse: 6.55195\n",
      "[1000]\tvalid_set's rmse: 6.49061\n",
      "[1000]\tvalid_set's rmse: 6.6078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-6.5384\t = Validation score   (-root_mean_squared_error)\n",
      "\t31.22s\t = Training   runtime\n",
      "\t2.82s\t = Validation runtime\n",
      "Fitting model: LightGBM_4_BAG_L1 ... Training model for up to 38309.79s of the 57519.25s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with SequentialLocalFoldFittingStrategy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's rmse: 6.6109\n",
      "[2000]\tvalid_set's rmse: 6.54221\n",
      "[1000]\tvalid_set's rmse: 6.63034\n",
      "[2000]\tvalid_set's rmse: 6.55958\n",
      "[1000]\tvalid_set's rmse: 6.60948\n",
      "[2000]\tvalid_set's rmse: 6.51224\n",
      "[1000]\tvalid_set's rmse: 6.6031\n",
      "[2000]\tvalid_set's rmse: 6.53104\n",
      "[1000]\tvalid_set's rmse: 6.64823\n",
      "[2000]\tvalid_set's rmse: 6.57988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-6.5417\t = Validation score   (-root_mean_squared_error)\n",
      "\t50.13s\t = Training   runtime\n",
      "\t5.06s\t = Validation runtime\n",
      "Fitting model: RandomForest_BAG_L1 ... Training model for up to 38253.9s of the 57463.37s of remaining time.\n",
      "\t-8.0542\t = Validation score   (-root_mean_squared_error)\n",
      "\t21.94s\t = Training   runtime\n",
      "\t1.24s\t = Validation runtime\n",
      "Fitting model: RandomForest_2_BAG_L1 ... Training model for up to 38230.59s of the 57440.05s of remaining time.\n",
      "\t-8.8285\t = Validation score   (-root_mean_squared_error)\n",
      "\t19.08s\t = Training   runtime\n",
      "\t1.2s\t = Validation runtime\n",
      "Fitting model: RandomForest_3_BAG_L1 ... Training model for up to 38210.18s of the 57419.65s of remaining time.\n",
      "\t-9.5848\t = Validation score   (-root_mean_squared_error)\n",
      "\t14.99s\t = Training   runtime\n",
      "\t1.16s\t = Validation runtime\n",
      "Fitting model: RandomForest_4_BAG_L1 ... Training model for up to 38193.9s of the 57403.36s of remaining time.\n",
      "\t-10.7153\t = Validation score   (-root_mean_squared_error)\n",
      "\t12.02s\t = Training   runtime\n",
      "\t1.14s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 38180.61s of the 57390.08s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tTraining S1F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\tTraining S1F2 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\tTraining S1F3 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\tTraining S1F4 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\tTraining S1F5 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\t-6.3059\t = Validation score   (-root_mean_squared_error)\n",
      "\t363.41s\t = Training   runtime\n",
      "\t1.73s\t = Validation runtime\n",
      "Fitting model: CatBoost_2_BAG_L1 ... Training model for up to 37814.58s of the 57024.04s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tTraining S1F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\tTraining S1F2 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\tTraining S1F3 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\tTraining S1F4 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\tTraining S1F5 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\t-6.3234\t = Validation score   (-root_mean_squared_error)\n",
      "\t301.95s\t = Training   runtime\n",
      "\t1.57s\t = Validation runtime\n",
      "Fitting model: CatBoost_3_BAG_L1 ... Training model for up to 37510.53s of the 56719.99s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tTraining S1F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\tTraining S1F2 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\tTraining S1F3 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\tTraining S1F4 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\tTraining S1F5 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\t-6.3361\t = Validation score   (-root_mean_squared_error)\n",
      "\t404.31s\t = Training   runtime\n",
      "\t1.61s\t = Validation runtime\n",
      "Fitting model: CatBoost_4_BAG_L1 ... Training model for up to 37103.88s of the 56313.34s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tTraining S1F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\tTraining S1F2 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\tTraining S1F3 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\tTraining S1F4 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\tTraining S1F5 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\t-6.3463\t = Validation score   (-root_mean_squared_error)\n",
      "\t415.57s\t = Training   runtime\n",
      "\t1.48s\t = Validation runtime\n",
      "Fitting model: ExtraTrees_BAG_L1 ... Training model for up to 36686.19s of the 55895.65s of remaining time.\n",
      "\t-8.1995\t = Validation score   (-root_mean_squared_error)\n",
      "\t8.38s\t = Training   runtime\n",
      "\t1.28s\t = Validation runtime\n",
      "Fitting model: ExtraTrees_2_BAG_L1 ... Training model for up to 36676.38s of the 55885.84s of remaining time.\n",
      "\t-8.8861\t = Validation score   (-root_mean_squared_error)\n",
      "\t6.59s\t = Training   runtime\n",
      "\t1.23s\t = Validation runtime\n",
      "Fitting model: ExtraTrees_3_BAG_L1 ... Training model for up to 36668.43s of the 55877.89s of remaining time.\n",
      "\t-9.6998\t = Validation score   (-root_mean_squared_error)\n",
      "\t5.34s\t = Training   runtime\n",
      "\t1.26s\t = Validation runtime\n",
      "Fitting model: ExtraTrees_4_BAG_L1 ... Training model for up to 36661.71s of the 55871.17s of remaining time.\n",
      "\t-10.7448\t = Validation score   (-root_mean_squared_error)\n",
      "\t4.14s\t = Training   runtime\n",
      "\t1.18s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 36656.26s of the 55865.72s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-6.3867\t = Validation score   (-root_mean_squared_error)\n",
      "\t15.37s\t = Training   runtime\n",
      "\t0.94s\t = Validation runtime\n",
      "Fitting model: XGBoost_2_BAG_L1 ... Training model for up to 36639.77s of the 55849.23s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-6.4003\t = Validation score   (-root_mean_squared_error)\n",
      "\t19.35s\t = Training   runtime\n",
      "\t1.03s\t = Validation runtime\n",
      "Fitting model: XGBoost_3_BAG_L1 ... Training model for up to 36619.18s of the 55828.64s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-6.4086\t = Validation score   (-root_mean_squared_error)\n",
      "\t32.25s\t = Training   runtime\n",
      "\t1.29s\t = Validation runtime\n",
      "Fitting model: XGBoost_4_BAG_L1 ... Training model for up to 36585.29s of the 55794.75s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-6.4169\t = Validation score   (-root_mean_squared_error)\n",
      "\t44.9s\t = Training   runtime\n",
      "\t1.38s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 3839.01s of the 55747.97s of remaining time.\n",
      "\tEnsemble Weights: {'CatBoost_BAG_L1': 0.545, 'LightGBM_BAG_L1': 0.136, 'XGBoost_BAG_L1': 0.136, 'XGBoost_3_BAG_L1': 0.091, 'LightGBM_4_BAG_L1': 0.045, 'XGBoost_4_BAG_L1': 0.045}\n",
      "\t-6.2677\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.17s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Included models: ['CAT', 'XGB', 'GBM', 'RF', 'XT'] (Specified by `included_model_types`, all other model types will be skipped)\n",
      "Fitting 20 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ... Training model for up to 55747.77s of the 55747.74s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-6.3056\t = Validation score   (-root_mean_squared_error)\n",
      "\t11.33s\t = Training   runtime\n",
      "\t0.34s\t = Validation runtime\n",
      "Fitting model: LightGBM_2_BAG_L2 ... Training model for up to 55735.85s of the 55735.81s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-6.2963\t = Validation score   (-root_mean_squared_error)\n",
      "\t11.32s\t = Training   runtime\n",
      "\t0.33s\t = Validation runtime\n",
      "Fitting model: LightGBM_3_BAG_L2 ... Training model for up to 55723.92s of the 55723.88s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-6.2898\t = Validation score   (-root_mean_squared_error)\n",
      "\t9.06s\t = Training   runtime\n",
      "\t0.28s\t = Validation runtime\n",
      "Fitting model: LightGBM_4_BAG_L2 ... Training model for up to 55714.32s of the 55714.28s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-6.2889\t = Validation score   (-root_mean_squared_error)\n",
      "\t8.25s\t = Training   runtime\n",
      "\t0.25s\t = Validation runtime\n",
      "Fitting model: RandomForest_BAG_L2 ... Training model for up to 55705.58s of the 55705.54s of remaining time.\n",
      "\t-6.2685\t = Validation score   (-root_mean_squared_error)\n",
      "\t95.49s\t = Training   runtime\n",
      "\t2.17s\t = Validation runtime\n",
      "Fitting model: RandomForest_2_BAG_L2 ... Training model for up to 55607.71s of the 55607.67s of remaining time.\n",
      "\t-6.2854\t = Validation score   (-root_mean_squared_error)\n",
      "\t83.52s\t = Training   runtime\n",
      "\t2.36s\t = Validation runtime\n",
      "Fitting model: RandomForest_3_BAG_L2 ... Training model for up to 55521.63s of the 55521.59s of remaining time.\n",
      "\t-6.3421\t = Validation score   (-root_mean_squared_error)\n",
      "\t65.28s\t = Training   runtime\n",
      "\t1.79s\t = Validation runtime\n",
      "Fitting model: RandomForest_4_BAG_L2 ... Training model for up to 55454.37s of the 55454.33s of remaining time.\n",
      "\t-6.6258\t = Validation score   (-root_mean_squared_error)\n",
      "\t49.58s\t = Training   runtime\n",
      "\t1.52s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L2 ... Training model for up to 55403.09s of the 55403.05s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tTraining S1F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\tTraining S1F2 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\tTraining S1F3 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\tTraining S1F4 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\tTraining S1F5 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\t-6.2426\t = Validation score   (-root_mean_squared_error)\n",
      "\t152.71s\t = Training   runtime\n",
      "\t0.87s\t = Validation runtime\n",
      "Fitting model: CatBoost_2_BAG_L2 ... Training model for up to 55249.17s of the 55249.13s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tTraining S1F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\tTraining S1F2 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\tTraining S1F3 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\tTraining S1F4 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\tTraining S1F5 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\t-6.2431\t = Validation score   (-root_mean_squared_error)\n",
      "\t162.41s\t = Training   runtime\n",
      "\t0.81s\t = Validation runtime\n",
      "Fitting model: CatBoost_3_BAG_L2 ... Training model for up to 55085.57s of the 55085.53s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tTraining S1F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\tTraining S1F2 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\tTraining S1F3 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\tTraining S1F4 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\tTraining S1F5 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\t-6.2488\t = Validation score   (-root_mean_squared_error)\n",
      "\t130.69s\t = Training   runtime\n",
      "\t0.71s\t = Validation runtime\n",
      "Fitting model: CatBoost_4_BAG_L2 ... Training model for up to 54953.86s of the 54953.82s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tTraining S1F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\tTraining S1F2 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\tTraining S1F3 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\tTraining S1F4 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\tTraining S1F5 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\t-6.2571\t = Validation score   (-root_mean_squared_error)\n",
      "\t99.17s\t = Training   runtime\n",
      "\t0.58s\t = Validation runtime\n",
      "Fitting model: ExtraTrees_BAG_L2 ... Training model for up to 54853.85s of the 54853.81s of remaining time.\n",
      "\t-6.2657\t = Validation score   (-root_mean_squared_error)\n",
      "\t11.17s\t = Training   runtime\n",
      "\t1.68s\t = Validation runtime\n",
      "Fitting model: ExtraTrees_2_BAG_L2 ... Training model for up to 54840.81s of the 54840.77s of remaining time.\n",
      "\t-6.2733\t = Validation score   (-root_mean_squared_error)\n",
      "\t9.79s\t = Training   runtime\n",
      "\t1.49s\t = Validation runtime\n",
      "Fitting model: ExtraTrees_3_BAG_L2 ... Training model for up to 54829.34s of the 54829.31s of remaining time.\n",
      "\t-6.2953\t = Validation score   (-root_mean_squared_error)\n",
      "\t7.46s\t = Training   runtime\n",
      "\t1.45s\t = Validation runtime\n",
      "Fitting model: ExtraTrees_4_BAG_L2 ... Training model for up to 54820.25s of the 54820.21s of remaining time.\n",
      "\t-6.3955\t = Validation score   (-root_mean_squared_error)\n",
      "\t5.69s\t = Training   runtime\n",
      "\t1.4s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L2 ... Training model for up to 54812.97s of the 54812.94s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-6.2425\t = Validation score   (-root_mean_squared_error)\n",
      "\t9.42s\t = Training   runtime\n",
      "\t1.1s\t = Validation runtime\n",
      "Fitting model: XGBoost_2_BAG_L2 ... Training model for up to 54802.22s of the 54802.18s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-6.2412\t = Validation score   (-root_mean_squared_error)\n",
      "\t9.33s\t = Training   runtime\n",
      "\t0.85s\t = Validation runtime\n",
      "Fitting model: XGBoost_3_BAG_L2 ... Training model for up to 54791.77s of the 54791.73s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-6.2466\t = Validation score   (-root_mean_squared_error)\n",
      "\t9.74s\t = Training   runtime\n",
      "\t0.88s\t = Validation runtime\n",
      "Fitting model: XGBoost_4_BAG_L2 ... Training model for up to 54780.92s of the 54780.88s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-6.2519\t = Validation score   (-root_mean_squared_error)\n",
      "\t11.39s\t = Training   runtime\n",
      "\t0.9s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 5574.78s of the 54768.31s of remaining time.\n",
      "\tEnsemble Weights: {'XGBoost_BAG_L2': 0.333, 'CatBoost_BAG_L2': 0.25, 'CatBoost_2_BAG_L2': 0.208, 'XGBoost_2_BAG_L2': 0.125, 'CatBoost_BAG_L1': 0.042, 'XGBoost_BAG_L1': 0.042}\n",
      "\t-6.229\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.2s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 2831.96s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 481.7 rows/s (13025 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20240915_181740\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<autogluon.tabular.predictor.predictor.TabularPredictor at 0x7d85fa653610>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_limit = 3600*16\n",
    "\n",
    "predictor = TabularPredictor(label=Config.target_col, problem_type='regression', eval_metric='root_mean_squared_error')\n",
    "predictor.fit(train_df, presets='medium_quality', time_limit=time_limit, num_bag_folds=5, num_bag_sets=1, num_stack_levels=1, dynamic_stacking=False,\n",
    "           included_model_types=['CAT', 'XGB', 'GBM', 'RF', 'XT'], ag_args_fit={'num_gpus': 1, 'num_cpus': 4},\n",
    "           hyperparameters = {\n",
    "              'GBM': [\n",
    "                    {'max_depth': 6, 'device': 'cpu'},\n",
    "                    {'max_depth': 5, 'device': 'cpu'},\n",
    "                    {'max_depth': 4, 'device': 'cpu'},\n",
    "                    {'max_depth': 3, 'device': 'cpu'},\n",
    "              ],\n",
    "              'XGB': [\n",
    "                  {'max_depth': 6},\n",
    "                  {'max_depth': 5},\n",
    "                  {'max_depth': 4},\n",
    "                  {'max_depth': 3},\n",
    "#                   {'max_depth': 2},\n",
    "              ],\n",
    "              'CAT': [\n",
    "                  {'depth': 6},\n",
    "                  {'depth': 5},\n",
    "                  {'depth': 4},\n",
    "                  {'depth': 3},\n",
    "#                   {'depth': 2},\n",
    "              ],\n",
    "              'RF': [\n",
    "                  {'max_depth': 6},\n",
    "                  {'max_depth': 5},\n",
    "                  {'max_depth': 4},\n",
    "                  {'max_depth': 3},\n",
    "#                   {'depth': 2},\n",
    "              ],\n",
    "              'XT': [\n",
    "                  {'max_depth': 6},\n",
    "                  {'max_depth': 5},\n",
    "                  {'max_depth': 4},\n",
    "                  {'max_depth': 3},\n",
    "#                   {'depth': 2},\n",
    "              ],\n",
    "           }\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4240e7a6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-15T19:04:52.620767Z",
     "iopub.status.busy": "2024-09-15T19:04:52.620449Z",
     "iopub.status.idle": "2024-09-15T19:04:52.657265Z",
     "shell.execute_reply": "2024-09-15T19:04:52.656392Z"
    },
    "papermill": {
     "duration": 0.075309,
     "end_time": "2024-09-15T19:04:52.659172",
     "exception": false,
     "start_time": "2024-09-15T19:04:52.583863",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_val</th>\n",
       "      <th>eval_metric</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WeightedEnsemble_L3</td>\n",
       "      <td>-6.228961</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>34.785135</td>\n",
       "      <td>2146.895152</td>\n",
       "      <td>0.001203</td>\n",
       "      <td>0.201734</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XGBoost_2_BAG_L2</td>\n",
       "      <td>-6.241165</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>32.001021</td>\n",
       "      <td>1822.158880</td>\n",
       "      <td>0.854028</td>\n",
       "      <td>9.333592</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBoost_BAG_L2</td>\n",
       "      <td>-6.242535</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>32.247615</td>\n",
       "      <td>1822.246212</td>\n",
       "      <td>1.100622</td>\n",
       "      <td>9.420924</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CatBoost_BAG_L2</td>\n",
       "      <td>-6.242591</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>32.015239</td>\n",
       "      <td>1965.532296</td>\n",
       "      <td>0.868246</td>\n",
       "      <td>152.707009</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CatBoost_2_BAG_L2</td>\n",
       "      <td>-6.243133</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>31.961035</td>\n",
       "      <td>1975.231893</td>\n",
       "      <td>0.814043</td>\n",
       "      <td>162.406605</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XGBoost_3_BAG_L2</td>\n",
       "      <td>-6.246603</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>32.023358</td>\n",
       "      <td>1822.563193</td>\n",
       "      <td>0.876366</td>\n",
       "      <td>9.737905</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CatBoost_3_BAG_L2</td>\n",
       "      <td>-6.248764</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>31.853551</td>\n",
       "      <td>1943.518439</td>\n",
       "      <td>0.706558</td>\n",
       "      <td>130.693151</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>XGBoost_4_BAG_L2</td>\n",
       "      <td>-6.251863</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>32.050136</td>\n",
       "      <td>1824.215117</td>\n",
       "      <td>0.903143</td>\n",
       "      <td>11.389829</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>CatBoost_4_BAG_L2</td>\n",
       "      <td>-6.257130</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>31.727331</td>\n",
       "      <td>1911.994879</td>\n",
       "      <td>0.580339</td>\n",
       "      <td>99.169592</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ExtraTrees_BAG_L2</td>\n",
       "      <td>-6.265675</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>32.829750</td>\n",
       "      <td>1823.993661</td>\n",
       "      <td>1.682757</td>\n",
       "      <td>11.168373</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>WeightedEnsemble_L2</td>\n",
       "      <td>-6.267675</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>11.557268</td>\n",
       "      <td>525.959955</td>\n",
       "      <td>0.001152</td>\n",
       "      <td>0.173620</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>RandomForest_BAG_L2</td>\n",
       "      <td>-6.268465</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>33.316262</td>\n",
       "      <td>1908.318488</td>\n",
       "      <td>2.169270</td>\n",
       "      <td>95.493201</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ExtraTrees_2_BAG_L2</td>\n",
       "      <td>-6.273317</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>32.639530</td>\n",
       "      <td>1822.614748</td>\n",
       "      <td>1.492538</td>\n",
       "      <td>9.789461</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>RandomForest_2_BAG_L2</td>\n",
       "      <td>-6.285379</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>33.509363</td>\n",
       "      <td>1896.349156</td>\n",
       "      <td>2.362371</td>\n",
       "      <td>83.523868</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>LightGBM_4_BAG_L2</td>\n",
       "      <td>-6.288870</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>31.393184</td>\n",
       "      <td>1821.072059</td>\n",
       "      <td>0.246192</td>\n",
       "      <td>8.246771</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>LightGBM_3_BAG_L2</td>\n",
       "      <td>-6.289809</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>31.429840</td>\n",
       "      <td>1821.883242</td>\n",
       "      <td>0.282848</td>\n",
       "      <td>9.057955</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ExtraTrees_3_BAG_L2</td>\n",
       "      <td>-6.295306</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>32.601393</td>\n",
       "      <td>1820.280572</td>\n",
       "      <td>1.454401</td>\n",
       "      <td>7.455285</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>LightGBM_2_BAG_L2</td>\n",
       "      <td>-6.296312</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>31.480151</td>\n",
       "      <td>1824.149655</td>\n",
       "      <td>0.333158</td>\n",
       "      <td>11.324367</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>LightGBM_BAG_L2</td>\n",
       "      <td>-6.305594</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>31.483231</td>\n",
       "      <td>1824.154364</td>\n",
       "      <td>0.336238</td>\n",
       "      <td>11.329077</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>CatBoost_BAG_L1</td>\n",
       "      <td>-6.305854</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>1.732997</td>\n",
       "      <td>363.409632</td>\n",
       "      <td>1.732997</td>\n",
       "      <td>363.409632</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>CatBoost_2_BAG_L1</td>\n",
       "      <td>-6.323429</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>1.569403</td>\n",
       "      <td>301.954415</td>\n",
       "      <td>1.569403</td>\n",
       "      <td>301.954415</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>CatBoost_3_BAG_L1</td>\n",
       "      <td>-6.336053</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>1.612766</td>\n",
       "      <td>404.308204</td>\n",
       "      <td>1.612766</td>\n",
       "      <td>404.308204</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>RandomForest_3_BAG_L2</td>\n",
       "      <td>-6.342128</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>32.935622</td>\n",
       "      <td>1878.104051</td>\n",
       "      <td>1.788629</td>\n",
       "      <td>65.278764</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>CatBoost_4_BAG_L1</td>\n",
       "      <td>-6.346304</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>1.481265</td>\n",
       "      <td>415.565442</td>\n",
       "      <td>1.481265</td>\n",
       "      <td>415.565442</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>XGBoost_BAG_L1</td>\n",
       "      <td>-6.386739</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.944337</td>\n",
       "      <td>15.368862</td>\n",
       "      <td>0.944337</td>\n",
       "      <td>15.368862</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>ExtraTrees_4_BAG_L2</td>\n",
       "      <td>-6.395518</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>32.548923</td>\n",
       "      <td>1818.519083</td>\n",
       "      <td>1.401930</td>\n",
       "      <td>5.693795</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>XGBoost_2_BAG_L1</td>\n",
       "      <td>-6.400290</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>1.029660</td>\n",
       "      <td>19.348605</td>\n",
       "      <td>1.029660</td>\n",
       "      <td>19.348605</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>XGBoost_3_BAG_L1</td>\n",
       "      <td>-6.408638</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>1.285301</td>\n",
       "      <td>32.252412</td>\n",
       "      <td>1.285301</td>\n",
       "      <td>32.252412</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>XGBoost_4_BAG_L1</td>\n",
       "      <td>-6.416942</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>1.379001</td>\n",
       "      <td>44.900146</td>\n",
       "      <td>1.379001</td>\n",
       "      <td>44.900146</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>LightGBM_BAG_L1</td>\n",
       "      <td>-6.444124</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>1.154159</td>\n",
       "      <td>19.724102</td>\n",
       "      <td>1.154159</td>\n",
       "      <td>19.724102</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>LightGBM_2_BAG_L1</td>\n",
       "      <td>-6.474355</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>1.397858</td>\n",
       "      <td>22.170118</td>\n",
       "      <td>1.397858</td>\n",
       "      <td>22.170118</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>LightGBM_3_BAG_L1</td>\n",
       "      <td>-6.538401</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>2.819559</td>\n",
       "      <td>31.222322</td>\n",
       "      <td>2.819559</td>\n",
       "      <td>31.222322</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>LightGBM_4_BAG_L1</td>\n",
       "      <td>-6.541728</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>5.060321</td>\n",
       "      <td>50.131181</td>\n",
       "      <td>5.060321</td>\n",
       "      <td>50.131181</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>RandomForest_4_BAG_L2</td>\n",
       "      <td>-6.625806</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>32.667809</td>\n",
       "      <td>1862.405082</td>\n",
       "      <td>1.520816</td>\n",
       "      <td>49.579794</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>RandomForest_BAG_L1</td>\n",
       "      <td>-8.054168</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>1.238426</td>\n",
       "      <td>21.941828</td>\n",
       "      <td>1.238426</td>\n",
       "      <td>21.941828</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>ExtraTrees_BAG_L1</td>\n",
       "      <td>-8.199545</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>1.277547</td>\n",
       "      <td>8.383278</td>\n",
       "      <td>1.277547</td>\n",
       "      <td>8.383278</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>RandomForest_2_BAG_L1</td>\n",
       "      <td>-8.828542</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>1.196445</td>\n",
       "      <td>19.076990</td>\n",
       "      <td>1.196445</td>\n",
       "      <td>19.076990</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>ExtraTrees_2_BAG_L1</td>\n",
       "      <td>-8.886113</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>1.233741</td>\n",
       "      <td>6.585283</td>\n",
       "      <td>1.233741</td>\n",
       "      <td>6.585283</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>RandomForest_3_BAG_L1</td>\n",
       "      <td>-9.584770</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>1.163400</td>\n",
       "      <td>14.992814</td>\n",
       "      <td>1.163400</td>\n",
       "      <td>14.992814</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>ExtraTrees_3_BAG_L1</td>\n",
       "      <td>-9.699800</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>1.255462</td>\n",
       "      <td>5.336274</td>\n",
       "      <td>1.255462</td>\n",
       "      <td>5.336274</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>RandomForest_4_BAG_L1</td>\n",
       "      <td>-10.715349</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>1.136512</td>\n",
       "      <td>12.017287</td>\n",
       "      <td>1.136512</td>\n",
       "      <td>12.017287</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>ExtraTrees_4_BAG_L1</td>\n",
       "      <td>-10.744849</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>1.178834</td>\n",
       "      <td>4.136094</td>\n",
       "      <td>1.178834</td>\n",
       "      <td>4.136094</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    model  score_val              eval_metric  pred_time_val     fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
       "0     WeightedEnsemble_L3  -6.228961  root_mean_squared_error      34.785135  2146.895152                0.001203           0.201734            3       True         42\n",
       "1        XGBoost_2_BAG_L2  -6.241165  root_mean_squared_error      32.001021  1822.158880                0.854028           9.333592            2       True         39\n",
       "2          XGBoost_BAG_L2  -6.242535  root_mean_squared_error      32.247615  1822.246212                1.100622           9.420924            2       True         38\n",
       "3         CatBoost_BAG_L2  -6.242591  root_mean_squared_error      32.015239  1965.532296                0.868246         152.707009            2       True         30\n",
       "4       CatBoost_2_BAG_L2  -6.243133  root_mean_squared_error      31.961035  1975.231893                0.814043         162.406605            2       True         31\n",
       "5        XGBoost_3_BAG_L2  -6.246603  root_mean_squared_error      32.023358  1822.563193                0.876366           9.737905            2       True         40\n",
       "6       CatBoost_3_BAG_L2  -6.248764  root_mean_squared_error      31.853551  1943.518439                0.706558         130.693151            2       True         32\n",
       "7        XGBoost_4_BAG_L2  -6.251863  root_mean_squared_error      32.050136  1824.215117                0.903143          11.389829            2       True         41\n",
       "8       CatBoost_4_BAG_L2  -6.257130  root_mean_squared_error      31.727331  1911.994879                0.580339          99.169592            2       True         33\n",
       "9       ExtraTrees_BAG_L2  -6.265675  root_mean_squared_error      32.829750  1823.993661                1.682757          11.168373            2       True         34\n",
       "10    WeightedEnsemble_L2  -6.267675  root_mean_squared_error      11.557268   525.959955                0.001152           0.173620            2       True         21\n",
       "11    RandomForest_BAG_L2  -6.268465  root_mean_squared_error      33.316262  1908.318488                2.169270          95.493201            2       True         26\n",
       "12    ExtraTrees_2_BAG_L2  -6.273317  root_mean_squared_error      32.639530  1822.614748                1.492538           9.789461            2       True         35\n",
       "13  RandomForest_2_BAG_L2  -6.285379  root_mean_squared_error      33.509363  1896.349156                2.362371          83.523868            2       True         27\n",
       "14      LightGBM_4_BAG_L2  -6.288870  root_mean_squared_error      31.393184  1821.072059                0.246192           8.246771            2       True         25\n",
       "15      LightGBM_3_BAG_L2  -6.289809  root_mean_squared_error      31.429840  1821.883242                0.282848           9.057955            2       True         24\n",
       "16    ExtraTrees_3_BAG_L2  -6.295306  root_mean_squared_error      32.601393  1820.280572                1.454401           7.455285            2       True         36\n",
       "17      LightGBM_2_BAG_L2  -6.296312  root_mean_squared_error      31.480151  1824.149655                0.333158          11.324367            2       True         23\n",
       "18        LightGBM_BAG_L2  -6.305594  root_mean_squared_error      31.483231  1824.154364                0.336238          11.329077            2       True         22\n",
       "19        CatBoost_BAG_L1  -6.305854  root_mean_squared_error       1.732997   363.409632                1.732997         363.409632            1       True          9\n",
       "20      CatBoost_2_BAG_L1  -6.323429  root_mean_squared_error       1.569403   301.954415                1.569403         301.954415            1       True         10\n",
       "21      CatBoost_3_BAG_L1  -6.336053  root_mean_squared_error       1.612766   404.308204                1.612766         404.308204            1       True         11\n",
       "22  RandomForest_3_BAG_L2  -6.342128  root_mean_squared_error      32.935622  1878.104051                1.788629          65.278764            2       True         28\n",
       "23      CatBoost_4_BAG_L1  -6.346304  root_mean_squared_error       1.481265   415.565442                1.481265         415.565442            1       True         12\n",
       "24         XGBoost_BAG_L1  -6.386739  root_mean_squared_error       0.944337    15.368862                0.944337          15.368862            1       True         17\n",
       "25    ExtraTrees_4_BAG_L2  -6.395518  root_mean_squared_error      32.548923  1818.519083                1.401930           5.693795            2       True         37\n",
       "26       XGBoost_2_BAG_L1  -6.400290  root_mean_squared_error       1.029660    19.348605                1.029660          19.348605            1       True         18\n",
       "27       XGBoost_3_BAG_L1  -6.408638  root_mean_squared_error       1.285301    32.252412                1.285301          32.252412            1       True         19\n",
       "28       XGBoost_4_BAG_L1  -6.416942  root_mean_squared_error       1.379001    44.900146                1.379001          44.900146            1       True         20\n",
       "29        LightGBM_BAG_L1  -6.444124  root_mean_squared_error       1.154159    19.724102                1.154159          19.724102            1       True          1\n",
       "30      LightGBM_2_BAG_L1  -6.474355  root_mean_squared_error       1.397858    22.170118                1.397858          22.170118            1       True          2\n",
       "31      LightGBM_3_BAG_L1  -6.538401  root_mean_squared_error       2.819559    31.222322                2.819559          31.222322            1       True          3\n",
       "32      LightGBM_4_BAG_L1  -6.541728  root_mean_squared_error       5.060321    50.131181                5.060321          50.131181            1       True          4\n",
       "33  RandomForest_4_BAG_L2  -6.625806  root_mean_squared_error      32.667809  1862.405082                1.520816          49.579794            2       True         29\n",
       "34    RandomForest_BAG_L1  -8.054168  root_mean_squared_error       1.238426    21.941828                1.238426          21.941828            1       True          5\n",
       "35      ExtraTrees_BAG_L1  -8.199545  root_mean_squared_error       1.277547     8.383278                1.277547           8.383278            1       True         13\n",
       "36  RandomForest_2_BAG_L1  -8.828542  root_mean_squared_error       1.196445    19.076990                1.196445          19.076990            1       True          6\n",
       "37    ExtraTrees_2_BAG_L1  -8.886113  root_mean_squared_error       1.233741     6.585283                1.233741           6.585283            1       True         14\n",
       "38  RandomForest_3_BAG_L1  -9.584770  root_mean_squared_error       1.163400    14.992814                1.163400          14.992814            1       True          7\n",
       "39    ExtraTrees_3_BAG_L1  -9.699800  root_mean_squared_error       1.255462     5.336274                1.255462           5.336274            1       True         15\n",
       "40  RandomForest_4_BAG_L1 -10.715349  root_mean_squared_error       1.136512    12.017287                1.136512          12.017287            1       True          8\n",
       "41    ExtraTrees_4_BAG_L1 -10.744849  root_mean_squared_error       1.178834     4.136094                1.178834           4.136094            1       True         16"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.leaderboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "03c04a98",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-15T19:04:52.732871Z",
     "iopub.status.busy": "2024-09-15T19:04:52.732576Z",
     "iopub.status.idle": "2024-09-15T19:54:27.911336Z",
     "shell.execute_reply": "2024-09-15T19:54:27.910556Z"
    },
    "papermill": {
     "duration": 2975.217521,
     "end_time": "2024-09-15T19:54:27.913264",
     "exception": false,
     "start_time": "2024-09-15T19:04:52.695743",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Refitting models via `predictor.refit_full` using all of the data (combined train and validation)...\n",
      "\tModels trained in this way will have the suffix \"_FULL\" and have NaN validation score.\n",
      "\tThis process is not bound by time_limit, but should take less time than the original `predictor.fit` call.\n",
      "\tTo learn more, refer to the `.refit_full` method docstring which explains how \"_FULL\" models differ from normal models.\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: CatBoost_BAG_L1_FULL ...\n",
      "\t644.46s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: XGBoost_BAG_L1_FULL ...\n",
      "\t4.55s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1_FULL ...\n",
      "\t3.85s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_2_BAG_L1_FULL ...\n",
      "\t4.46s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_3_BAG_L1_FULL ...\n",
      "\t7.0s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_4_BAG_L1_FULL ...\n",
      "\t11.89s\t = Training   runtime\n",
      "Fitting model: RandomForest_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t21.94s\t = Training   runtime\n",
      "\t1.24s\t = Validation runtime\n",
      "Fitting model: RandomForest_2_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t19.08s\t = Training   runtime\n",
      "\t1.2s\t = Validation runtime\n",
      "Fitting model: RandomForest_3_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t14.99s\t = Training   runtime\n",
      "\t1.16s\t = Validation runtime\n",
      "Fitting model: RandomForest_4_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t12.02s\t = Training   runtime\n",
      "\t1.14s\t = Validation runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: CatBoost_2_BAG_L1_FULL ...\n",
      "\t516.69s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: CatBoost_3_BAG_L1_FULL ...\n",
      "\t619.57s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: CatBoost_4_BAG_L1_FULL ...\n",
      "\t639.98s\t = Training   runtime\n",
      "Fitting model: ExtraTrees_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t8.38s\t = Training   runtime\n",
      "\t1.28s\t = Validation runtime\n",
      "Fitting model: ExtraTrees_2_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t6.59s\t = Training   runtime\n",
      "\t1.23s\t = Validation runtime\n",
      "Fitting model: ExtraTrees_3_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t5.34s\t = Training   runtime\n",
      "\t1.26s\t = Validation runtime\n",
      "Fitting model: ExtraTrees_4_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t4.14s\t = Training   runtime\n",
      "\t1.18s\t = Validation runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: XGBoost_2_BAG_L1_FULL ...\n",
      "\t5.54s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: XGBoost_3_BAG_L1_FULL ...\n",
      "\t9.6s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: XGBoost_4_BAG_L1_FULL ...\n",
      "\t13.81s\t = Training   runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: CatBoost_BAG_L2_FULL ...\n",
      "\t239.62s\t = Training   runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: CatBoost_2_BAG_L2_FULL ...\n",
      "\t245.02s\t = Training   runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: XGBoost_BAG_L2_FULL ...\n",
      "\t2.44s\t = Training   runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: XGBoost_2_BAG_L2_FULL ...\n",
      "\t2.31s\t = Training   runtime\n",
      "Fitting model: WeightedEnsemble_L3_FULL | Skipping fit via cloning parent ...\n",
      "\tEnsemble Weights: {'XGBoost_BAG_L2': 0.333, 'CatBoost_BAG_L2': 0.25, 'CatBoost_2_BAG_L2': 0.208, 'XGBoost_2_BAG_L2': 0.125, 'CatBoost_BAG_L1': 0.042, 'XGBoost_BAG_L1': 0.042}\n",
      "\t0.2s\t = Training   runtime\n",
      "Updated best model to \"WeightedEnsemble_L3_FULL\" (Previously \"WeightedEnsemble_L3\"). AutoGluon will default to using \"WeightedEnsemble_L3_FULL\" for predict() and predict_proba().\n",
      "Refit complete, total runtime = 2975.17s ... Best model: \"WeightedEnsemble_L3_FULL\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'CatBoost_BAG_L1': 'CatBoost_BAG_L1_FULL',\n",
       " 'XGBoost_BAG_L1': 'XGBoost_BAG_L1_FULL',\n",
       " 'LightGBM_BAG_L1': 'LightGBM_BAG_L1_FULL',\n",
       " 'LightGBM_2_BAG_L1': 'LightGBM_2_BAG_L1_FULL',\n",
       " 'LightGBM_3_BAG_L1': 'LightGBM_3_BAG_L1_FULL',\n",
       " 'LightGBM_4_BAG_L1': 'LightGBM_4_BAG_L1_FULL',\n",
       " 'RandomForest_BAG_L1': 'RandomForest_BAG_L1_FULL',\n",
       " 'RandomForest_2_BAG_L1': 'RandomForest_2_BAG_L1_FULL',\n",
       " 'RandomForest_3_BAG_L1': 'RandomForest_3_BAG_L1_FULL',\n",
       " 'RandomForest_4_BAG_L1': 'RandomForest_4_BAG_L1_FULL',\n",
       " 'CatBoost_2_BAG_L1': 'CatBoost_2_BAG_L1_FULL',\n",
       " 'CatBoost_3_BAG_L1': 'CatBoost_3_BAG_L1_FULL',\n",
       " 'CatBoost_4_BAG_L1': 'CatBoost_4_BAG_L1_FULL',\n",
       " 'ExtraTrees_BAG_L1': 'ExtraTrees_BAG_L1_FULL',\n",
       " 'ExtraTrees_2_BAG_L1': 'ExtraTrees_2_BAG_L1_FULL',\n",
       " 'ExtraTrees_3_BAG_L1': 'ExtraTrees_3_BAG_L1_FULL',\n",
       " 'ExtraTrees_4_BAG_L1': 'ExtraTrees_4_BAG_L1_FULL',\n",
       " 'XGBoost_2_BAG_L1': 'XGBoost_2_BAG_L1_FULL',\n",
       " 'XGBoost_3_BAG_L1': 'XGBoost_3_BAG_L1_FULL',\n",
       " 'XGBoost_4_BAG_L1': 'XGBoost_4_BAG_L1_FULL',\n",
       " 'CatBoost_BAG_L2': 'CatBoost_BAG_L2_FULL',\n",
       " 'CatBoost_2_BAG_L2': 'CatBoost_2_BAG_L2_FULL',\n",
       " 'XGBoost_BAG_L2': 'XGBoost_BAG_L2_FULL',\n",
       " 'XGBoost_2_BAG_L2': 'XGBoost_2_BAG_L2_FULL',\n",
       " 'WeightedEnsemble_L3': 'WeightedEnsemble_L3_FULL'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.refit_full(model=\"best\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d0c55162",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-15T19:54:28.000904Z",
     "iopub.status.busy": "2024-09-15T19:54:28.000563Z",
     "iopub.status.idle": "2024-09-15T19:54:34.515203Z",
     "shell.execute_reply": "2024-09-15T19:54:34.514249Z"
    },
    "papermill": {
     "duration": 6.561146,
     "end_time": "2024-09-15T19:54:34.517769",
     "exception": false,
     "start_time": "2024-09-15T19:54:27.956623",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictions = predictor.predict(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4b31c8d5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-15T19:54:34.608053Z",
     "iopub.status.busy": "2024-09-15T19:54:34.607688Z",
     "iopub.status.idle": "2024-09-15T19:54:34.612828Z",
     "shell.execute_reply": "2024-09-15T19:54:34.611830Z"
    },
    "papermill": {
     "duration": 0.050881,
     "end_time": "2024-09-15T19:54:34.614775",
     "exception": false,
     "start_time": "2024-09-15T19:54:34.563894",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sub_df = pd.DataFrame({\n",
    "    'id': range(len(test_df)),\n",
    "    'Degerlendirme Puani': predictions\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "51a8b423",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-15T19:54:34.701632Z",
     "iopub.status.busy": "2024-09-15T19:54:34.700847Z",
     "iopub.status.idle": "2024-09-15T19:54:34.729520Z",
     "shell.execute_reply": "2024-09-15T19:54:34.728610Z"
    },
    "papermill": {
     "duration": 0.074432,
     "end_time": "2024-09-15T19:54:34.731695",
     "exception": false,
     "start_time": "2024-09-15T19:54:34.657263",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sub_df.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f7c66dc2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-15T19:54:34.818536Z",
     "iopub.status.busy": "2024-09-15T19:54:34.818183Z",
     "iopub.status.idle": "2024-09-15T19:54:34.831690Z",
     "shell.execute_reply": "2024-09-15T19:54:34.830821Z"
    },
    "papermill": {
     "duration": 0.058923,
     "end_time": "2024-09-15T19:54:34.833739",
     "exception": false,
     "start_time": "2024-09-15T19:54:34.774816",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Degerlendirme Puani</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>32.958546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>20.865759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>8.486250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>18.391670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>42.647633</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  Degerlendirme Puani\n",
       "0   0            32.958546\n",
       "1   1            20.865759\n",
       "2   2             8.486250\n",
       "3   3            18.391670\n",
       "4   4            42.647633"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub = pd.read_csv('/kaggle/working/submission.csv')\n",
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c95051",
   "metadata": {
    "papermill": {
     "duration": 0.044031,
     "end_time": "2024-09-15T19:54:34.922027",
     "exception": false,
     "start_time": "2024-09-15T19:54:34.877996",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 9495861,
     "sourceId": 84622,
     "sourceType": "competition"
    },
    {
     "datasetId": 5358948,
     "sourceId": 8912136,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5676029,
     "sourceId": 9361303,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30762,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 6006.066325,
   "end_time": "2024-09-15T19:54:37.302376",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-09-15T18:14:31.236051",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
